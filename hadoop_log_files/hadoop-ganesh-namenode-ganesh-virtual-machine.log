2023-02-07 21:26:19,611 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-07 21:26:19,623 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-07 21:26:19,630 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2023-02-07 21:26:20,047 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-07 21:26:20,249 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-07 21:26:20,250 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2023-02-07 21:26:20,289 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2023-02-07 21:26:20,292 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2023-02-07 21:26:20,626 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-07 21:26:20,646 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2023-02-07 21:26:20,729 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-07 21:26:20,765 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-07 21:26:20,773 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2023-02-07 21:26:20,780 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-07 21:26:20,783 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-02-07 21:26:20,783 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-07 21:26:20,783 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-07 21:26:21,027 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2023-02-07 21:26:21,029 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-02-07 21:26:21,068 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2023-02-07 21:26:21,068 INFO org.mortbay.log: jetty-6.1.26
2023-02-07 21:26:21,309 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2023-02-07 21:26:21,347 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-07 21:26:21,348 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-07 21:26:21,348 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-07 21:26:21,348 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-07 21:26:21,355 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-07 21:26:21,355 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-07 21:26:21,451 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2023-02-07 21:26:21,468 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2023-02-07 21:26:21,471 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2023-02-07 21:26:21,475 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2023-02-07 21:26:21,542 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2023-02-07 21:26:21,542 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2023-02-07 21:26:21,544 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-02-07 21:26:21,545 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Feb 07 21:26:21
2023-02-07 21:26:21,547 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2023-02-07 21:26:21,547 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-07 21:26:21,550 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2023-02-07 21:26:21,550 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2023-02-07 21:26:21,605 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2023-02-07 21:26:21,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2023-02-07 21:26:21,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2023-02-07 21:26:21,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2023-02-07 21:26:21,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2023-02-07 21:26:21,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2023-02-07 21:26:21,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2023-02-07 21:26:21,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2023-02-07 21:26:21,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ganesh (auth:SIMPLE)
2023-02-07 21:26:21,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2023-02-07 21:26:21,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2023-02-07 21:26:21,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2023-02-07 21:26:21,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2023-02-07 21:26:21,706 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2023-02-07 21:26:21,706 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-07 21:26:21,706 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2023-02-07 21:26:21,706 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2023-02-07 21:26:21,737 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2023-02-07 21:26:21,737 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2023-02-07 21:26:21,737 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2023-02-07 21:26:21,751 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2023-02-07 21:26:21,751 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-07 21:26:21,752 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2023-02-07 21:26:21,752 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2023-02-07 21:26:21,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2023-02-07 21:26:21,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2023-02-07 21:26:21,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2023-02-07 21:26:21,760 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-02-07 21:26:21,760 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2023-02-07 21:26:21,760 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-02-07 21:26:21,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2023-02-07 21:26:21,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-02-07 21:26:21,768 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2023-02-07 21:26:21,768 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-07 21:26:21,768 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2023-02-07 21:26:21,768 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2023-02-07 21:26:21,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ganesh/Desktop/HADOOP_F1/in_use.lock acquired by nodename 8524@ganesh-virtual-machine
2023-02-07 21:26:21,932 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ganesh/Desktop/HADOOP_F1/current
2023-02-07 21:26:21,933 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2023-02-07 21:26:21,933 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-02-07 21:26:21,996 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2023-02-07 21:26:22,033 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2023-02-07 21:26:22,033 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000000
2023-02-07 21:26:22,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-02-07 21:26:22,039 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2023-02-07 21:26:22,172 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2023-02-07 21:26:22,172 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 399 msecs
2023-02-07 21:26:22,539 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2023-02-07 21:26:22,547 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-07 21:26:22,572 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2023-02-07 21:26:22,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2023-02-07 21:26:22,682 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-07 21:26:22,703 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2023-02-07 21:26:22,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2023-02-07 21:26:22,704 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2023-02-07 21:26:22,704 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2023-02-07 21:26:22,704 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2023-02-07 21:26:22,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2023-02-07 21:26:22,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2023-02-07 21:26:22,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2023-02-07 21:26:22,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2023-02-07 21:26:22,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2023-02-07 21:26:22,753 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 45 msec
2023-02-07 21:26:22,799 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-07 21:26:22,800 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2023-02-07 21:26:22,804 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2023-02-07 21:26:22,809 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2023-02-07 21:26:22,809 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2023-02-07 21:26:22,816 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 7 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2023-02-07 21:26:22,822 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-02-07 21:26:34,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519) storage 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-07 21:26:34,983 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2023-02-07 21:26:34,983 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 4e10373a-8afa-4846-a4e7-48202a2a517c (127.0.0.1:50010).
2023-02-07 21:26:35,109 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 for DN 127.0.0.1:50010
2023-02-07 21:26:35,277 INFO BlockStateChange: BLOCK* processReport 0x5ac794d0482a412d: Processing first storage report for DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 from datanode 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-07 21:26:35,279 INFO BlockStateChange: BLOCK* processReport 0x5ac794d0482a412d: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2023-02-07 21:27:41,536 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-07 21:27:41,537 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-07 21:27:41,538 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1, 1
2023-02-07 21:27:41,538 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=2 lastSyncedTxid=1 mostRecentTxid=2
2023-02-07 21:27:41,538 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2023-02-07 21:27:41,539 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=2 lastSyncedTxid=2 mostRecentTxid=2
2023-02-07 21:27:41,539 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 6 
2023-02-07 21:27:41,545 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000001 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000001-0000000000000000002
2023-02-07 21:27:41,687 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2023-02-07 21:27:43,385 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2023-02-07 21:27:43,385 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000002 size 323 bytes.
2023-02-07 21:27:43,395 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2023-02-07 22:10:41,129 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-07 22:10:41,138 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-15 22:32:15,754 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-15 22:32:15,769 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-15 22:32:15,783 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2023-02-15 22:32:16,281 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-15 22:32:16,537 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-15 22:32:16,537 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2023-02-15 22:32:16,591 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2023-02-15 22:32:16,594 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2023-02-15 22:32:17,014 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-15 22:32:17,035 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2023-02-15 22:32:17,180 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-15 22:32:17,201 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-15 22:32:17,238 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2023-02-15 22:32:17,247 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-15 22:32:17,250 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-02-15 22:32:17,250 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-15 22:32:17,251 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-15 22:32:17,648 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2023-02-15 22:32:17,650 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-02-15 22:32:17,720 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2023-02-15 22:32:17,720 INFO org.mortbay.log: jetty-6.1.26
2023-02-15 22:32:18,106 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2023-02-15 22:32:18,170 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-15 22:32:18,170 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-15 22:32:18,170 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-15 22:32:18,170 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-15 22:32:18,178 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-15 22:32:18,178 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-15 22:32:18,230 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2023-02-15 22:32:18,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2023-02-15 22:32:18,245 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2023-02-15 22:32:18,247 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2023-02-15 22:32:18,309 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2023-02-15 22:32:18,310 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2023-02-15 22:32:18,311 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-02-15 22:32:18,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Feb 15 22:32:18
2023-02-15 22:32:18,314 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2023-02-15 22:32:18,314 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-15 22:32:18,316 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2023-02-15 22:32:18,316 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2023-02-15 22:32:18,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2023-02-15 22:32:18,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2023-02-15 22:32:18,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2023-02-15 22:32:18,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2023-02-15 22:32:18,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2023-02-15 22:32:18,347 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2023-02-15 22:32:18,347 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2023-02-15 22:32:18,347 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2023-02-15 22:32:18,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ganesh (auth:SIMPLE)
2023-02-15 22:32:18,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2023-02-15 22:32:18,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2023-02-15 22:32:18,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2023-02-15 22:32:18,357 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2023-02-15 22:32:18,487 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2023-02-15 22:32:18,487 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-15 22:32:18,488 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2023-02-15 22:32:18,488 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2023-02-15 22:32:18,489 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2023-02-15 22:32:18,489 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2023-02-15 22:32:18,490 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2023-02-15 22:32:18,501 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2023-02-15 22:32:18,502 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-15 22:32:18,503 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2023-02-15 22:32:18,503 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2023-02-15 22:32:18,507 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2023-02-15 22:32:18,507 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2023-02-15 22:32:18,507 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2023-02-15 22:32:18,512 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-02-15 22:32:18,512 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2023-02-15 22:32:18,512 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-02-15 22:32:18,518 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2023-02-15 22:32:18,519 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-02-15 22:32:18,523 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2023-02-15 22:32:18,523 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-15 22:32:18,523 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2023-02-15 22:32:18,523 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2023-02-15 22:32:18,543 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ganesh/Desktop/HADOOP_F1/in_use.lock acquired by nodename 6231@ganesh-virtual-machine
2023-02-15 22:32:18,723 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ganesh/Desktop/HADOOP_F1/current
2023-02-15 22:32:18,768 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000003 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000003-0000000000000000003
2023-02-15 22:32:18,841 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2023-02-15 22:32:19,106 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2023-02-15 22:32:19,267 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2023-02-15 22:32:19,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2 from /home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000002
2023-02-15 22:32:19,275 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7b8233cd expecting start txid #3
2023-02-15 22:32:19,275 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000003-0000000000000000003
2023-02-15 22:32:19,277 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000003-0000000000000000003' to transaction ID 3
2023-02-15 22:32:19,307 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000003-0000000000000000003 of size 1048576 edits # 1 loaded in 0 seconds
2023-02-15 22:32:19,309 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2023-02-15 22:32:19,310 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2023-02-15 22:32:19,317 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000003 using no compression
2023-02-15 22:32:19,366 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000003 of size 323 bytes saved in 0 seconds.
2023-02-15 22:32:19,381 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2023-02-15 22:32:19,381 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-02-15 22:32:19,399 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4
2023-02-15 22:32:19,538 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem write lock held for 1010 ms via
java.lang.Thread.getStackTrace(Thread.java:1564)
org.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:1032)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:233)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.writeUnlock(FSNamesystem.java:1537)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1041)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:691)
org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:634)
org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:695)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:898)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:877)
org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1603)
org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1671)
	Number of suppressed write-lock reports: 0
	Longest write-lock held interval: 1010
2023-02-15 22:32:19,538 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2023-02-15 22:32:19,538 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1010 msecs
2023-02-15 22:32:19,925 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2023-02-15 22:32:19,938 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-15 22:32:19,958 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2023-02-15 22:32:20,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2023-02-15 22:32:20,100 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-15 22:32:20,117 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2023-02-15 22:32:20,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2023-02-15 22:32:20,118 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2023-02-15 22:32:20,118 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2023-02-15 22:32:20,118 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2023-02-15 22:32:20,197 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2023-02-15 22:32:20,197 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2023-02-15 22:32:20,197 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2023-02-15 22:32:20,197 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2023-02-15 22:32:20,197 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2023-02-15 22:32:20,197 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 73 msec
2023-02-15 22:32:20,276 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2023-02-15 22:32:20,271 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-15 22:32:20,273 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2023-02-15 22:32:20,285 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2023-02-15 22:32:20,285 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2023-02-15 22:32:20,291 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2023-02-15 22:32:20,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-02-15 22:32:28,051 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519) storage 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-15 22:32:28,052 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2023-02-15 22:32:28,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 4e10373a-8afa-4846-a4e7-48202a2a517c (127.0.0.1:50010).
2023-02-15 22:32:28,278 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 for DN 127.0.0.1:50010
2023-02-15 22:32:28,466 INFO BlockStateChange: BLOCK* processReport 0x5cbefda32fee946e: Processing first storage report for DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 from datanode 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-15 22:32:28,471 INFO BlockStateChange: BLOCK* processReport 0x5cbefda32fee946e: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 0, hasStaleStorage: false, processing time: 5 msecs, invalidatedBlocks: 0
2023-02-15 22:33:36,206 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-15 22:33:36,206 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-15 22:33:36,206 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4, 4
2023-02-15 22:33:36,207 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=5 lastSyncedTxid=4 mostRecentTxid=5
2023-02-15 22:33:36,207 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 3 Number of syncs: 2 SyncTimes(ms): 5 
2023-02-15 22:33:36,210 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=5 lastSyncedTxid=5 mostRecentTxid=5
2023-02-15 22:33:36,210 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 3 Number of syncs: 3 SyncTimes(ms): 8 
2023-02-15 22:33:36,212 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000004 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000004-0000000000000000005
2023-02-15 22:33:36,212 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 6
2023-02-15 22:33:37,691 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2023-02-15 22:33:37,692 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000005 size 323 bytes.
2023-02-15 22:33:37,699 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3
2023-02-15 22:33:37,699 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2023-02-15 22:48:29,249 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-15 22:48:29,574 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-19 21:42:47,943 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-19 21:42:47,964 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-19 21:42:47,974 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2023-02-19 21:42:48,479 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-19 21:42:48,768 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-19 21:42:48,769 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2023-02-19 21:42:48,803 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2023-02-19 21:42:48,807 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2023-02-19 21:42:49,428 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-19 21:42:49,474 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2023-02-19 21:42:49,624 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-19 21:42:49,645 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-19 21:42:49,672 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2023-02-19 21:42:49,682 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-19 21:42:49,700 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-02-19 21:42:49,700 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-19 21:42:49,701 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-19 21:42:50,200 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2023-02-19 21:42:50,202 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-02-19 21:42:50,260 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2023-02-19 21:42:50,260 INFO org.mortbay.log: jetty-6.1.26
2023-02-19 21:42:50,615 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2023-02-19 21:42:50,658 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-19 21:42:50,658 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-19 21:42:50,659 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-19 21:42:50,659 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-19 21:42:50,664 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-19 21:42:50,665 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-19 21:42:50,715 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2023-02-19 21:42:50,732 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2023-02-19 21:42:50,734 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2023-02-19 21:42:50,737 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2023-02-19 21:42:50,813 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2023-02-19 21:42:50,813 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2023-02-19 21:42:50,816 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-02-19 21:42:50,816 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Feb 19 21:42:50
2023-02-19 21:42:50,819 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2023-02-19 21:42:50,819 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-19 21:42:50,821 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2023-02-19 21:42:50,821 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2023-02-19 21:42:50,982 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2023-02-19 21:42:50,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2023-02-19 21:42:50,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2023-02-19 21:42:51,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2023-02-19 21:42:51,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2023-02-19 21:42:51,007 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2023-02-19 21:42:51,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2023-02-19 21:42:51,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2023-02-19 21:42:51,050 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ganesh (auth:SIMPLE)
2023-02-19 21:42:51,050 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2023-02-19 21:42:51,050 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2023-02-19 21:42:51,050 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2023-02-19 21:42:51,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2023-02-19 21:42:51,403 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2023-02-19 21:42:51,403 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-19 21:42:51,403 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2023-02-19 21:42:51,404 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2023-02-19 21:42:51,562 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2023-02-19 21:42:51,562 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2023-02-19 21:42:51,562 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2023-02-19 21:42:51,576 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2023-02-19 21:42:51,576 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-19 21:42:51,576 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2023-02-19 21:42:51,576 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2023-02-19 21:42:51,579 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2023-02-19 21:42:51,579 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2023-02-19 21:42:51,579 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2023-02-19 21:42:51,584 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-02-19 21:42:51,584 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2023-02-19 21:42:51,585 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-02-19 21:42:51,588 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2023-02-19 21:42:51,588 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-02-19 21:42:51,593 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2023-02-19 21:42:51,593 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-19 21:42:51,594 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2023-02-19 21:42:51,594 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2023-02-19 21:42:51,612 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ganesh/Desktop/HADOOP_F1/in_use.lock acquired by nodename 2928@ganesh-virtual-machine
2023-02-19 21:42:51,810 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ganesh/Desktop/HADOOP_F1/current
2023-02-19 21:42:51,884 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000006 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000006-0000000000000000006
2023-02-19 21:42:51,975 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000005, cpktTxId=0000000000000000005)
2023-02-19 21:42:52,056 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2023-02-19 21:42:52,096 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2023-02-19 21:42:52,097 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 5 from /home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000005
2023-02-19 21:42:52,097 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7b8233cd expecting start txid #6
2023-02-19 21:42:52,097 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000006-0000000000000000006
2023-02-19 21:42:52,101 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000006-0000000000000000006' to transaction ID 6
2023-02-19 21:42:52,123 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000006-0000000000000000006 of size 1048576 edits # 1 loaded in 0 seconds
2023-02-19 21:42:52,124 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2023-02-19 21:42:52,125 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2023-02-19 21:42:52,134 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000006 using no compression
2023-02-19 21:42:52,192 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000006 of size 323 bytes saved in 0 seconds.
2023-02-19 21:42:52,209 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5
2023-02-19 21:42:52,209 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000003, cpktTxId=0000000000000000003)
2023-02-19 21:42:52,224 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 7
2023-02-19 21:42:52,363 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2023-02-19 21:42:52,363 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 765 msecs
2023-02-19 21:42:52,709 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2023-02-19 21:42:52,725 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-19 21:42:52,769 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2023-02-19 21:42:52,920 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2023-02-19 21:42:52,921 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-19 21:42:52,948 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2023-02-19 21:42:52,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2023-02-19 21:42:52,949 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 2 secs
2023-02-19 21:42:52,950 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2023-02-19 21:42:52,950 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2023-02-19 21:42:52,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2023-02-19 21:42:52,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2023-02-19 21:42:52,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2023-02-19 21:42:52,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2023-02-19 21:42:52,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2023-02-19 21:42:52,990 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 40 msec
2023-02-19 21:42:53,114 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2023-02-19 21:42:53,109 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-19 21:42:53,159 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2023-02-19 21:42:53,182 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2023-02-19 21:42:53,183 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2023-02-19 21:42:53,202 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 19 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2023-02-19 21:42:53,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-02-19 21:43:01,474 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519) storage 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-19 21:43:01,476 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2023-02-19 21:43:01,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 4e10373a-8afa-4846-a4e7-48202a2a517c (127.0.0.1:50010).
2023-02-19 21:43:01,915 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 for DN 127.0.0.1:50010
2023-02-19 21:43:02,053 INFO BlockStateChange: BLOCK* processReport 0x358ed62705febb98: Processing first storage report for DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 from datanode 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-19 21:43:02,057 INFO BlockStateChange: BLOCK* processReport 0x358ed62705febb98: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 0, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2023-02-19 21:44:14,434 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 6 Total time for transactions(ms): 83 Number of transactions batched in Syncs: 6 Number of syncs: 2 SyncTimes(ms): 16 
2023-02-19 22:09:34,496 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1010ms
No GCs detected
2023-02-19 22:11:17,755 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1132ms
No GCs detected
2023-02-19 22:12:04,841 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 9 Total time for transactions(ms): 86 Number of transactions batched in Syncs: 10 Number of syncs: 5 SyncTimes(ms): 22 
2023-02-19 22:12:05,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:50010 for /hbase/.tmp/hbase.version
2023-02-19 22:12:05,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/.tmp/hbase.version
2023-02-19 22:12:05,647 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2023-02-19 22:12:06,069 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/hbase.version is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:06,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:50010 for /hbase/.tmp/hbase.id
2023-02-19 22:12:06,179 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/hbase.id is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:06,532 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:50010 for /hbase/data/hbase/meta/1588230740/.regioninfo
2023-02-19 22:12:06,572 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/.regioninfo is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:06,828 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:06,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:50010 for /hbase/data/hbase/meta/.tmp/.tableinfo.0000000001
2023-02-19 22:12:06,900 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:07,776 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:50010 for /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673.default.1676866327746
2023-02-19 22:12:07,808 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673.default.1676866327746 for DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:13,015 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:50010 for /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673..meta.1676866333003.meta
2023-02-19 22:12:13,039 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673..meta.1676866333003.meta for DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:13,344 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/recovered.edits/3.seqid is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:13,457 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:50010 for /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673..meta.1676866333433.meta
2023-02-19 22:12:13,482 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673..meta.1676866333433.meta for DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:13,498 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673..meta.1676866333003.meta is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:13,867 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:50010 for /hbase/MasterProcWALs/state-00000000000000000001.log
2023-02-19 22:12:13,893 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/MasterProcWALs/state-00000000000000000001.log for DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:14,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:50010 for /hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001
2023-02-19 22:12:14,095 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741833_1009 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001
2023-02-19 22:12:14,503 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:14,557 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:50010 for /hbase/.tmp/data/hbase/namespace/c9bb21c94cf81bcbf77b536c9f0ba27a/.regioninfo
2023-02-19 22:12:14,578 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/hbase/namespace/c9bb21c94cf81bcbf77b536c9f0ba27a/.regioninfo is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:15,954 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1135ms
No GCs detected
2023-02-19 22:12:16,054 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:50010 for /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673..meta.1676866336027.meta
2023-02-19 22:12:16,080 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673..meta.1676866336027.meta for DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:16,109 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673..meta.1676866333433.meta is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:16,328 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/namespace/c9bb21c94cf81bcbf77b536c9f0ba27a/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:16,350 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:50010 for /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673.default.1676866336339
2023-02-19 22:12:16,370 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673.default.1676866336339 for DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:16,383 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673.default.1676866327746 is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:16,412 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:50010 for /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673..meta.1676866336401.meta
2023-02-19 22:12:16,432 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673..meta.1676866336401.meta for DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:16,465 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673..meta.1676866336027.meta is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:16,563 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:50010 for /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673.default.1676866336556
2023-02-19 22:12:16,602 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673.default.1676866336556 for DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:16,615 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673.default.1676866336339 is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-19 22:12:37,523 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/MasterProcWALs/state-00000000000000000001.log is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-20 00:19:19,459 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:50010 for /hbase/MasterProcWALs/state-00000000000000000002.log
2023-02-20 00:19:19,460 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 130 Total time for transactions(ms): 97 Number of transactions batched in Syncs: 50 Number of syncs: 84 SyncTimes(ms): 107 
2023-02-20 00:19:19,471 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/MasterProcWALs/state-00000000000000000002.log is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-20 00:19:19,880 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673..meta.1676866336401.meta is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-20 00:19:19,889 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741838_1014 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673.default.1676866336556
2023-02-20 00:19:20,293 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/WALs/ganesh-virtual-machine,43723,1676866324673/ganesh-virtual-machine%2C43723%2C1676866324673.default.1676866336556 is closed by DFSClient_NONMAPREDUCE_141585002_1
2023-02-20 00:35:39,186 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-20 00:35:39,187 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-20 00:35:39,187 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 7, 139
2023-02-20 00:35:39,187 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=140 lastSyncedTxid=139 mostRecentTxid=140
2023-02-20 00:35:39,188 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 134 Total time for transactions(ms): 98 Number of transactions batched in Syncs: 52 Number of syncs: 88 SyncTimes(ms): 110 
2023-02-20 00:35:39,188 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=140 lastSyncedTxid=140 mostRecentTxid=140
2023-02-20 00:35:39,188 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 134 Total time for transactions(ms): 98 Number of transactions batched in Syncs: 52 Number of syncs: 89 SyncTimes(ms): 110 
2023-02-20 00:35:39,195 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000007 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000007-0000000000000000140
2023-02-20 00:35:39,196 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 141
2023-02-20 00:35:42,616 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 750.00 KB/s
2023-02-20 00:35:42,617 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000140 size 3813 bytes.
2023-02-20 00:35:42,624 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 6
2023-02-20 00:35:42,624 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000005, cpktTxId=0000000000000000005)
2023-02-20 00:46:18,147 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-20 00:46:18,260 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-21 13:06:26,366 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-21 13:06:26,385 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-21 13:06:26,396 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2023-02-21 13:06:26,866 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-21 13:06:27,199 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-21 13:06:27,199 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2023-02-21 13:06:27,239 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2023-02-21 13:06:27,243 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2023-02-21 13:06:27,865 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-21 13:06:27,920 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2023-02-21 13:06:28,076 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-21 13:06:28,102 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-21 13:06:28,123 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2023-02-21 13:06:28,133 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-21 13:06:28,151 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-02-21 13:06:28,151 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-21 13:06:28,151 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-21 13:06:28,509 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2023-02-21 13:06:28,511 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-02-21 13:06:28,589 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2023-02-21 13:06:28,589 INFO org.mortbay.log: jetty-6.1.26
2023-02-21 13:06:28,882 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2023-02-21 13:06:28,937 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-21 13:06:28,938 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-21 13:06:28,938 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-21 13:06:28,938 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-21 13:06:28,944 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-21 13:06:28,944 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-21 13:06:28,998 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2023-02-21 13:06:29,013 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2023-02-21 13:06:29,015 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2023-02-21 13:06:29,017 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2023-02-21 13:06:29,086 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2023-02-21 13:06:29,086 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2023-02-21 13:06:29,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-02-21 13:06:29,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Feb 21 13:06:29
2023-02-21 13:06:29,091 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2023-02-21 13:06:29,091 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-21 13:06:29,093 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2023-02-21 13:06:29,093 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2023-02-21 13:06:29,115 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2023-02-21 13:06:29,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2023-02-21 13:06:29,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2023-02-21 13:06:29,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2023-02-21 13:06:29,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2023-02-21 13:06:29,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2023-02-21 13:06:29,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2023-02-21 13:06:29,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2023-02-21 13:06:29,126 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ganesh (auth:SIMPLE)
2023-02-21 13:06:29,126 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2023-02-21 13:06:29,126 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2023-02-21 13:06:29,126 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2023-02-21 13:06:29,128 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2023-02-21 13:06:29,229 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2023-02-21 13:06:29,229 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-21 13:06:29,229 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2023-02-21 13:06:29,229 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2023-02-21 13:06:29,230 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2023-02-21 13:06:29,230 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2023-02-21 13:06:29,230 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2023-02-21 13:06:29,241 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2023-02-21 13:06:29,242 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-21 13:06:29,242 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2023-02-21 13:06:29,242 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2023-02-21 13:06:29,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2023-02-21 13:06:29,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2023-02-21 13:06:29,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2023-02-21 13:06:29,249 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-02-21 13:06:29,249 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2023-02-21 13:06:29,249 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-02-21 13:06:29,254 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2023-02-21 13:06:29,254 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-02-21 13:06:29,262 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2023-02-21 13:06:29,262 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-21 13:06:29,262 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2023-02-21 13:06:29,263 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2023-02-21 13:06:29,308 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ganesh/Desktop/HADOOP_F1/in_use.lock acquired by nodename 3628@ganesh-virtual-machine
2023-02-21 13:06:29,821 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ganesh/Desktop/HADOOP_F1/current
2023-02-21 13:06:29,896 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000141 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000141-0000000000000000141
2023-02-21 13:06:29,994 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000140, cpktTxId=0000000000000000140)
2023-02-21 13:06:30,111 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 46 INodes.
2023-02-21 13:06:30,209 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2023-02-21 13:06:30,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 140 from /home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000140
2023-02-21 13:06:30,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7b8233cd expecting start txid #141
2023-02-21 13:06:30,211 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000141-0000000000000000141
2023-02-21 13:06:30,214 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000141-0000000000000000141' to transaction ID 141
2023-02-21 13:06:30,232 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000141-0000000000000000141 of size 1048576 edits # 1 loaded in 0 seconds
2023-02-21 13:06:30,233 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2023-02-21 13:06:30,233 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2023-02-21 13:06:30,244 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000141 using no compression
2023-02-21 13:06:30,318 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000141 of size 3813 bytes saved in 0 seconds.
2023-02-21 13:06:30,336 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 140
2023-02-21 13:06:30,336 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000006, cpktTxId=0000000000000000006)
2023-02-21 13:06:30,375 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 142
2023-02-21 13:06:30,564 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem write lock held for 1287 ms via
java.lang.Thread.getStackTrace(Thread.java:1564)
org.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:1032)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:233)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.writeUnlock(FSNamesystem.java:1537)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1041)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:691)
org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:634)
org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:695)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:898)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:877)
org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1603)
org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1671)
	Number of suppressed write-lock reports: 0
	Longest write-lock held interval: 1287
2023-02-21 13:06:30,564 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2023-02-21 13:06:30,565 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1288 msecs
2023-02-21 13:06:31,223 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2023-02-21 13:06:31,243 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-21 13:06:31,295 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2023-02-21 13:06:31,576 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2023-02-21 13:06:31,578 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-21 13:06:31,603 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2023-02-21 13:06:31,603 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 13 blocks to reach the threshold 0.9990 of total blocks 14.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2023-02-21 13:06:31,679 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-21 13:06:31,681 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2023-02-21 13:06:31,698 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2023-02-21 13:06:31,704 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2023-02-21 13:06:31,704 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2023-02-21 13:06:31,725 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 21 milliseconds
name space=46
storage space=8700
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2023-02-21 13:06:31,744 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-02-21 13:06:41,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519) storage 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-21 13:06:41,148 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2023-02-21 13:06:41,148 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 4e10373a-8afa-4846-a4e7-48202a2a517c (127.0.0.1:50010).
2023-02-21 13:06:41,599 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 for DN 127.0.0.1:50010
2023-02-21 13:06:41,698 INFO BlockStateChange: BLOCK* processReport 0xcdcdb6e2a21396f0: Processing first storage report for DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 from datanode 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-21 13:06:41,704 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 13 has reached the threshold 0.9990 of total blocks 14. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2023-02-21 13:06:41,704 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2023-02-21 13:06:41,706 INFO BlockStateChange: BLOCK* processReport 0xcdcdb6e2a21396f0: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 14, hasStaleStorage: false, processing time: 9 msecs, invalidatedBlocks: 0
2023-02-21 13:06:41,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 14
2023-02-21 13:06:41,723 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2023-02-21 13:06:41,723 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 13
2023-02-21 13:06:41,723 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2023-02-21 13:06:41,723 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2023-02-21 13:06:41,723 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2023-02-21 13:07:01,724 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 14 has reached the threshold 0.9990 of total blocks 14. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2023-02-21 13:07:11,730 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 42 secs
2023-02-21 13:07:11,730 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2023-02-21 13:07:11,731 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2023-02-21 13:07:11,731 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 14 blocks
2023-02-21 13:17:26,756 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-21 13:17:26,902 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-21 13:21:13,428 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-21 13:21:13,444 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-21 13:21:13,455 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2023-02-21 13:21:13,913 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-21 13:21:14,163 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-21 13:21:14,163 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2023-02-21 13:21:14,213 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2023-02-21 13:21:14,216 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2023-02-21 13:21:14,801 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-21 13:21:14,836 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2023-02-21 13:21:14,935 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-21 13:21:14,950 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-21 13:21:14,963 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2023-02-21 13:21:14,970 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-21 13:21:14,976 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-02-21 13:21:14,976 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-21 13:21:14,977 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-21 13:21:15,284 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2023-02-21 13:21:15,286 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-02-21 13:21:15,339 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2023-02-21 13:21:15,339 INFO org.mortbay.log: jetty-6.1.26
2023-02-21 13:21:15,564 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2023-02-21 13:21:15,617 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-21 13:21:15,618 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-21 13:21:15,618 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-21 13:21:15,618 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-21 13:21:15,624 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-21 13:21:15,625 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-21 13:21:15,700 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2023-02-21 13:21:15,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2023-02-21 13:21:15,733 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2023-02-21 13:21:15,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2023-02-21 13:21:15,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2023-02-21 13:21:15,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2023-02-21 13:21:15,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-02-21 13:21:15,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Feb 21 13:21:15
2023-02-21 13:21:15,876 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2023-02-21 13:21:15,876 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-21 13:21:15,878 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2023-02-21 13:21:15,879 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2023-02-21 13:21:16,051 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2023-02-21 13:21:16,055 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2023-02-21 13:21:16,055 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2023-02-21 13:21:16,055 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2023-02-21 13:21:16,055 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2023-02-21 13:21:16,055 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2023-02-21 13:21:16,055 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2023-02-21 13:21:16,055 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2023-02-21 13:21:16,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ganesh (auth:SIMPLE)
2023-02-21 13:21:16,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2023-02-21 13:21:16,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2023-02-21 13:21:16,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2023-02-21 13:21:16,077 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2023-02-21 13:21:16,285 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2023-02-21 13:21:16,285 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-21 13:21:16,285 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2023-02-21 13:21:16,286 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2023-02-21 13:21:16,383 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2023-02-21 13:21:16,384 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2023-02-21 13:21:16,384 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2023-02-21 13:21:16,398 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2023-02-21 13:21:16,398 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-21 13:21:16,399 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2023-02-21 13:21:16,399 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2023-02-21 13:21:16,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2023-02-21 13:21:16,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2023-02-21 13:21:16,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2023-02-21 13:21:16,407 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-02-21 13:21:16,407 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2023-02-21 13:21:16,407 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-02-21 13:21:16,412 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2023-02-21 13:21:16,412 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-02-21 13:21:16,418 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2023-02-21 13:21:16,418 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-21 13:21:16,419 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2023-02-21 13:21:16,419 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2023-02-21 13:21:16,595 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ganesh/Desktop/HADOOP_F1/in_use.lock acquired by nodename 2663@ganesh-virtual-machine
2023-02-21 13:21:16,638 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ganesh/Desktop/HADOOP_F1/current
2023-02-21 13:21:16,755 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000142 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000142-0000000000000000142
2023-02-21 13:21:17,046 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000141, cpktTxId=0000000000000000141)
2023-02-21 13:21:17,186 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 46 INodes.
2023-02-21 13:21:17,279 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2023-02-21 13:21:17,280 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 141 from /home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000141
2023-02-21 13:21:17,280 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7b8233cd expecting start txid #142
2023-02-21 13:21:17,280 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000142-0000000000000000142
2023-02-21 13:21:17,283 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000142-0000000000000000142' to transaction ID 142
2023-02-21 13:21:17,310 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000142-0000000000000000142 of size 1048576 edits # 1 loaded in 0 seconds
2023-02-21 13:21:17,311 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-02-21 13:21:17,311 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 143
2023-02-21 13:21:17,581 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem write lock held for 1158 ms via
java.lang.Thread.getStackTrace(Thread.java:1564)
org.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:1032)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:233)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.writeUnlock(FSNamesystem.java:1537)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1041)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:691)
org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:634)
org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:695)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:898)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:877)
org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1603)
org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1671)
	Number of suppressed write-lock reports: 0
	Longest write-lock held interval: 1158
2023-02-21 13:21:17,582 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2023-02-21 13:21:17,582 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1158 msecs
2023-02-21 13:21:18,049 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2023-02-21 13:21:18,059 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-21 13:21:18,084 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2023-02-21 13:21:18,212 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2023-02-21 13:21:18,217 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-21 13:21:18,249 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2023-02-21 13:21:18,250 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 13 blocks to reach the threshold 0.9990 of total blocks 14.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2023-02-21 13:21:18,351 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-21 13:21:18,355 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2023-02-21 13:21:18,370 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2023-02-21 13:21:18,380 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2023-02-21 13:21:18,380 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2023-02-21 13:21:18,398 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 18 milliseconds
name space=46
storage space=8700
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2023-02-21 13:21:18,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-02-21 13:21:26,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519) storage 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-21 13:21:26,917 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2023-02-21 13:21:26,917 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 4e10373a-8afa-4846-a4e7-48202a2a517c (127.0.0.1:50010).
2023-02-21 13:21:27,216 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 for DN 127.0.0.1:50010
2023-02-21 13:21:27,583 INFO BlockStateChange: BLOCK* processReport 0x734fb30e4af8b5c6: Processing first storage report for DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 from datanode 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-21 13:21:27,593 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 13 has reached the threshold 0.9990 of total blocks 14. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2023-02-21 13:21:27,593 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2023-02-21 13:21:27,596 INFO BlockStateChange: BLOCK* processReport 0x734fb30e4af8b5c6: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 14, hasStaleStorage: false, processing time: 13 msecs, invalidatedBlocks: 0
2023-02-21 13:21:27,616 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 14
2023-02-21 13:21:27,616 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2023-02-21 13:21:27,616 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 13
2023-02-21 13:21:27,616 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2023-02-21 13:21:27,617 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2023-02-21 13:21:27,617 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 18 msec
2023-02-21 13:21:47,604 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 14 has reached the threshold 0.9990 of total blocks 14. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2023-02-21 13:21:57,608 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 41 secs
2023-02-21 13:21:57,609 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2023-02-21 13:21:57,609 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2023-02-21 13:21:57,609 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 14 blocks
2023-02-21 15:40:36,141 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1016ms
No GCs detected
2023-02-21 15:42:06,466 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-21 15:42:06,521 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-23 12:30:33,869 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-23 12:30:33,906 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-23 12:30:33,921 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2023-02-23 12:30:34,757 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-23 12:30:35,205 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-23 12:30:35,205 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2023-02-23 12:30:35,269 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2023-02-23 12:30:35,278 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2023-02-23 12:30:36,225 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-23 12:30:36,241 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2023-02-23 12:30:36,322 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-23 12:30:36,332 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-23 12:30:36,342 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2023-02-23 12:30:36,350 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-23 12:30:36,353 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-02-23 12:30:36,353 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-23 12:30:36,353 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-23 12:30:36,757 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2023-02-23 12:30:36,767 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-02-23 12:30:36,846 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2023-02-23 12:30:36,846 INFO org.mortbay.log: jetty-6.1.26
2023-02-23 12:30:37,167 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2023-02-23 12:30:37,217 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-23 12:30:37,218 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-23 12:30:37,218 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-23 12:30:37,218 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-23 12:30:37,224 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-23 12:30:37,225 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-23 12:30:37,287 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2023-02-23 12:30:37,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2023-02-23 12:30:37,307 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2023-02-23 12:30:37,310 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2023-02-23 12:30:37,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2023-02-23 12:30:37,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2023-02-23 12:30:37,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-02-23 12:30:37,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Feb 23 12:30:37
2023-02-23 12:30:37,416 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2023-02-23 12:30:37,416 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-23 12:30:37,418 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2023-02-23 12:30:37,418 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2023-02-23 12:30:37,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2023-02-23 12:30:37,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2023-02-23 12:30:37,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2023-02-23 12:30:37,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2023-02-23 12:30:37,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2023-02-23 12:30:37,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2023-02-23 12:30:37,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2023-02-23 12:30:37,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2023-02-23 12:30:37,468 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ganesh (auth:SIMPLE)
2023-02-23 12:30:37,468 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2023-02-23 12:30:37,468 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2023-02-23 12:30:37,468 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2023-02-23 12:30:37,470 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2023-02-23 12:30:37,615 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2023-02-23 12:30:37,615 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-23 12:30:37,615 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2023-02-23 12:30:37,616 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2023-02-23 12:30:37,653 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2023-02-23 12:30:37,653 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2023-02-23 12:30:37,654 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2023-02-23 12:30:37,669 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2023-02-23 12:30:37,669 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-23 12:30:37,670 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2023-02-23 12:30:37,670 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2023-02-23 12:30:37,676 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2023-02-23 12:30:37,676 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2023-02-23 12:30:37,676 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2023-02-23 12:30:37,683 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-02-23 12:30:37,683 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2023-02-23 12:30:37,683 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-02-23 12:30:37,692 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2023-02-23 12:30:37,692 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-02-23 12:30:37,701 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2023-02-23 12:30:37,701 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-23 12:30:37,701 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2023-02-23 12:30:37,701 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2023-02-23 12:30:37,902 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ganesh/Desktop/HADOOP_F1/in_use.lock acquired by nodename 7139@ganesh-virtual-machine
2023-02-23 12:30:37,946 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ganesh/Desktop/HADOOP_F1/current
2023-02-23 12:30:38,002 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000143 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000143-0000000000000000143
2023-02-23 12:30:38,100 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000141, cpktTxId=0000000000000000141)
2023-02-23 12:30:38,177 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 46 INodes.
2023-02-23 12:30:38,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2023-02-23 12:30:38,269 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 141 from /home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000141
2023-02-23 12:30:38,270 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@72758afa expecting start txid #142
2023-02-23 12:30:38,270 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000142-0000000000000000142
2023-02-23 12:30:38,274 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000142-0000000000000000142' to transaction ID 142
2023-02-23 12:30:38,308 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000142-0000000000000000142 of size 1048576 edits # 1 loaded in 0 seconds
2023-02-23 12:30:38,308 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@fb9c7aa expecting start txid #143
2023-02-23 12:30:38,308 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000143-0000000000000000143
2023-02-23 12:30:38,309 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000143-0000000000000000143' to transaction ID 142
2023-02-23 12:30:38,310 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000143-0000000000000000143 of size 1048576 edits # 1 loaded in 0 seconds
2023-02-23 12:30:38,310 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2023-02-23 12:30:38,310 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2023-02-23 12:30:38,322 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000143 using no compression
2023-02-23 12:30:38,411 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000143 of size 3813 bytes saved in 0 seconds.
2023-02-23 12:30:38,425 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 141
2023-02-23 12:30:38,426 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000140, cpktTxId=0000000000000000140)
2023-02-23 12:30:38,439 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 144
2023-02-23 12:30:38,586 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2023-02-23 12:30:38,586 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 879 msecs
2023-02-23 12:30:38,980 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2023-02-23 12:30:38,991 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-23 12:30:39,031 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2023-02-23 12:30:39,128 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2023-02-23 12:30:39,135 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-23 12:30:39,166 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2023-02-23 12:30:39,167 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 13 blocks to reach the threshold 0.9990 of total blocks 14.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2023-02-23 12:30:39,342 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-23 12:30:39,343 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2023-02-23 12:30:39,353 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2023-02-23 12:30:39,367 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2023-02-23 12:30:39,367 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2023-02-23 12:30:39,399 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 32 milliseconds
name space=46
storage space=8700
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2023-02-23 12:30:39,435 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-02-23 12:30:47,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519) storage 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-23 12:30:47,576 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2023-02-23 12:30:47,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 4e10373a-8afa-4846-a4e7-48202a2a517c (127.0.0.1:50010).
2023-02-23 12:30:48,011 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 for DN 127.0.0.1:50010
2023-02-23 12:30:48,122 INFO BlockStateChange: BLOCK* processReport 0xec9f56963191d3de: Processing first storage report for DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 from datanode 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-23 12:30:48,141 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 13 has reached the threshold 0.9990 of total blocks 14. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2023-02-23 12:30:48,141 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2023-02-23 12:30:48,152 INFO BlockStateChange: BLOCK* processReport 0xec9f56963191d3de: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 14, hasStaleStorage: false, processing time: 29 msecs, invalidatedBlocks: 0
2023-02-23 12:30:48,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 14
2023-02-23 12:30:48,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2023-02-23 12:30:48,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 13
2023-02-23 12:30:48,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2023-02-23 12:30:48,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2023-02-23 12:30:48,162 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2023-02-23 12:31:08,166 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 14 has reached the threshold 0.9990 of total blocks 14. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2023-02-23 12:31:18,171 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 40 secs
2023-02-23 12:31:18,172 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2023-02-23 12:31:18,172 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2023-02-23 12:31:18,172 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 14 blocks
2023-02-23 12:42:14,951 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-23 12:42:14,980 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-23 22:21:20,957 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-23 22:21:20,972 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-23 22:21:20,983 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2023-02-23 22:21:21,609 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-23 22:21:21,847 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-23 22:21:21,848 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2023-02-23 22:21:21,875 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2023-02-23 22:21:21,879 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2023-02-23 22:21:22,306 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-23 22:21:22,330 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2023-02-23 22:21:22,401 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-23 22:21:22,413 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-23 22:21:22,424 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2023-02-23 22:21:22,433 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-23 22:21:22,435 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-02-23 22:21:22,436 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-23 22:21:22,436 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-23 22:21:22,671 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2023-02-23 22:21:22,674 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-02-23 22:21:22,738 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2023-02-23 22:21:22,738 INFO org.mortbay.log: jetty-6.1.26
2023-02-23 22:21:23,043 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2023-02-23 22:21:23,071 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-23 22:21:23,072 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-23 22:21:23,072 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-23 22:21:23,072 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-23 22:21:23,078 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-23 22:21:23,079 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-23 22:21:23,126 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2023-02-23 22:21:23,142 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2023-02-23 22:21:23,144 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2023-02-23 22:21:23,147 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2023-02-23 22:21:23,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2023-02-23 22:21:23,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2023-02-23 22:21:23,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-02-23 22:21:23,245 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Feb 23 22:21:23
2023-02-23 22:21:23,248 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2023-02-23 22:21:23,248 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-23 22:21:23,252 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2023-02-23 22:21:23,252 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2023-02-23 22:21:23,288 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2023-02-23 22:21:23,290 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2023-02-23 22:21:23,290 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2023-02-23 22:21:23,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2023-02-23 22:21:23,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2023-02-23 22:21:23,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2023-02-23 22:21:23,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2023-02-23 22:21:23,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2023-02-23 22:21:23,302 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ganesh (auth:SIMPLE)
2023-02-23 22:21:23,302 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2023-02-23 22:21:23,302 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2023-02-23 22:21:23,303 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2023-02-23 22:21:23,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2023-02-23 22:21:23,531 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2023-02-23 22:21:23,532 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-23 22:21:23,532 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2023-02-23 22:21:23,533 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2023-02-23 22:21:23,639 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2023-02-23 22:21:23,640 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2023-02-23 22:21:23,640 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2023-02-23 22:21:23,677 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2023-02-23 22:21:23,677 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-23 22:21:23,677 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2023-02-23 22:21:23,678 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2023-02-23 22:21:23,680 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2023-02-23 22:21:23,680 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2023-02-23 22:21:23,680 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2023-02-23 22:21:23,687 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-02-23 22:21:23,687 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2023-02-23 22:21:23,687 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-02-23 22:21:23,692 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2023-02-23 22:21:23,693 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-02-23 22:21:23,733 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2023-02-23 22:21:23,733 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-23 22:21:23,733 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2023-02-23 22:21:23,733 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2023-02-23 22:21:23,752 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ganesh/Desktop/HADOOP_F1/in_use.lock acquired by nodename 4673@ganesh-virtual-machine
2023-02-23 22:21:24,097 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ganesh/Desktop/HADOOP_F1/current
2023-02-23 22:21:24,288 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000144 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000144-0000000000000000144
2023-02-23 22:21:24,456 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000143, cpktTxId=0000000000000000143)
2023-02-23 22:21:24,565 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 46 INodes.
2023-02-23 22:21:24,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2023-02-23 22:21:24,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 143 from /home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000143
2023-02-23 22:21:24,719 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7b8233cd expecting start txid #144
2023-02-23 22:21:24,720 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000144-0000000000000000144
2023-02-23 22:21:24,722 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000144-0000000000000000144' to transaction ID 144
2023-02-23 22:21:24,738 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000144-0000000000000000144 of size 1048576 edits # 1 loaded in 0 seconds
2023-02-23 22:21:24,738 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2023-02-23 22:21:24,738 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2023-02-23 22:21:24,748 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000144 using no compression
2023-02-23 22:21:24,823 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000144 of size 3813 bytes saved in 0 seconds.
2023-02-23 22:21:24,869 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 143
2023-02-23 22:21:24,869 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000141, cpktTxId=0000000000000000141)
2023-02-23 22:21:24,950 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 145
2023-02-23 22:21:25,107 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem write lock held for 1369 ms via
java.lang.Thread.getStackTrace(Thread.java:1564)
org.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:1032)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:233)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.writeUnlock(FSNamesystem.java:1537)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1041)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:691)
org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:634)
org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:695)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:898)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:877)
org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1603)
org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1671)
	Number of suppressed write-lock reports: 0
	Longest write-lock held interval: 1369
2023-02-23 22:21:25,107 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2023-02-23 22:21:25,108 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1370 msecs
2023-02-23 22:21:25,547 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2023-02-23 22:21:25,560 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-23 22:21:25,595 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2023-02-23 22:21:25,734 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2023-02-23 22:21:25,736 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-23 22:21:25,766 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2023-02-23 22:21:25,767 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 13 blocks to reach the threshold 0.9990 of total blocks 14.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2023-02-23 22:21:25,841 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-23 22:21:25,846 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2023-02-23 22:21:25,859 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2023-02-23 22:21:25,875 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2023-02-23 22:21:25,875 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2023-02-23 22:21:25,908 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 32 milliseconds
name space=46
storage space=8700
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2023-02-23 22:21:25,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-02-23 22:21:35,023 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519) storage 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-23 22:21:35,024 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2023-02-23 22:21:35,025 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 4e10373a-8afa-4846-a4e7-48202a2a517c (127.0.0.1:50010).
2023-02-23 22:21:35,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 for DN 127.0.0.1:50010
2023-02-23 22:21:35,337 INFO BlockStateChange: BLOCK* processReport 0x1fbaa56fa204e33a: Processing first storage report for DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 from datanode 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-23 22:21:35,348 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 13 has reached the threshold 0.9990 of total blocks 14. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2023-02-23 22:21:35,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2023-02-23 22:21:35,350 INFO BlockStateChange: BLOCK* processReport 0x1fbaa56fa204e33a: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 14, hasStaleStorage: false, processing time: 13 msecs, invalidatedBlocks: 0
2023-02-23 22:21:35,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 14
2023-02-23 22:21:35,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2023-02-23 22:21:35,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 13
2023-02-23 22:21:35,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2023-02-23 22:21:35,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2023-02-23 22:21:35,369 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 19 msec
2023-02-23 22:21:55,374 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 14 has reached the threshold 0.9990 of total blocks 14. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2023-02-23 22:22:05,377 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 42 secs
2023-02-23 22:22:05,377 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2023-02-23 22:22:05,377 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2023-02-23 22:22:05,377 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 14 blocks
2023-02-23 22:26:10,203 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1469ms
No GCs detected
2023-02-23 22:35:54,097 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5033ms
No GCs detected
2023-02-23 22:36:06,018 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5391ms
No GCs detected
2023-02-23 22:36:18,362 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5391ms
No GCs detected
2023-02-23 22:36:47,336 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12957ms
No GCs detected
2023-02-23 22:49:26,199 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5066ms
No GCs detected
2023-02-23 22:49:32,278 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5067ms
No GCs detected
2023-02-23 22:49:41,372 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4988ms
No GCs detected
2023-02-23 22:49:45,018 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5225ms
No GCs detected
2023-02-23 22:49:58,878 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5399ms
No GCs detected
2023-02-23 22:50:10,971 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4968ms
No GCs detected
2023-02-23 22:50:16,090 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5245ms
No GCs detected
2023-02-23 22:50:24,143 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5425ms
No GCs detected
2023-02-23 22:50:29,070 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5080ms
No GCs detected
2023-02-23 22:50:36,418 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5329ms
No GCs detected
2023-02-23 22:50:42,224 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5332ms
No GCs detected
2023-02-23 22:50:49,137 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5351ms
No GCs detected
2023-02-23 22:50:54,906 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5316ms
No GCs detected
2023-02-23 22:51:11,473 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5414ms
No GCs detected
2023-02-23 22:51:21,711 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5299ms
No GCs detected
2023-02-23 22:52:49,687 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9341ms
No GCs detected
2023-02-23 22:54:22,345 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7736ms
No GCs detected
2023-02-23 22:54:54,800 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4962ms
No GCs detected
2023-02-23 22:58:09,462 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-23 22:58:09,462 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-23 22:58:09,462 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 145, 145
2023-02-23 22:58:09,463 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=146 lastSyncedTxid=145 mostRecentTxid=146
2023-02-23 22:58:09,463 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 144 Number of syncs: 2 SyncTimes(ms): 28 
2023-02-23 22:58:09,465 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=146 lastSyncedTxid=146 mostRecentTxid=146
2023-02-23 22:58:09,465 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 144 Number of syncs: 3 SyncTimes(ms): 29 
2023-02-23 22:58:09,468 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000145 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000145-0000000000000000146
2023-02-23 22:58:09,469 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 147
2023-02-23 22:58:11,318 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 750.00 KB/s
2023-02-23 22:58:11,318 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000146 size 3813 bytes.
2023-02-23 22:58:11,324 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 144
2023-02-23 22:58:11,324 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000143, cpktTxId=0000000000000000143)
2023-02-23 23:13:08,699 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2884ms
No GCs detected
2023-02-24 00:24:17,194 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 30 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 24 
2023-02-24 00:24:21,301 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016, replicas=127.0.0.1:50010 for /hbase/WALs/ganesh-virtual-machine,34387,1677219855819/ganesh-virtual-machine%2C34387%2C1677219855819.default.1677219861214
2023-02-24 00:24:21,470 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/ganesh-virtual-machine,34387,1677219855819/ganesh-virtual-machine%2C34387%2C1677219855819.default.1677219861214 for DFSClient_NONMAPREDUCE_1075336992_1
2023-02-24 00:24:23,705 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017, replicas=127.0.0.1:50010 for /hbase/WALs/ganesh-virtual-machine,34387,1677219855819/ganesh-virtual-machine%2C34387%2C1677219855819..meta.1677219863672.meta
2023-02-24 00:24:23,730 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/ganesh-virtual-machine,34387,1677219855819/ganesh-virtual-machine%2C34387%2C1677219855819..meta.1677219863672.meta for DFSClient_NONMAPREDUCE_1075336992_1
2023-02-24 00:24:24,419 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/recovered.edits/4.seqid is closed by DFSClient_NONMAPREDUCE_1075336992_1
2023-02-24 00:24:24,975 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018, replicas=127.0.0.1:50010 for /hbase/MasterProcWALs/state-00000000000000000003.log
2023-02-24 00:24:25,035 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/MasterProcWALs/state-00000000000000000003.log for DFSClient_NONMAPREDUCE_1075336992_1
2023-02-24 00:24:25,612 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019, replicas=127.0.0.1:50010 for /hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001
2023-02-24 00:24:25,664 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_1075336992_1
2023-02-24 00:24:25,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020, replicas=127.0.0.1:50010 for /hbase/.tmp/data/hbase/namespace/b0378fa05cd004597410c72b0f55d9b0/.regioninfo
2023-02-24 00:24:25,750 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/hbase/namespace/b0378fa05cd004597410c72b0f55d9b0/.regioninfo is closed by DFSClient_NONMAPREDUCE_1075336992_1
2023-02-24 00:24:26,282 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/namespace/b0378fa05cd004597410c72b0f55d9b0/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_1075336992_1
2023-02-24 00:24:26,728 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000, call Call#135 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 127.0.0.1:55024
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/hbase/WALs/ganesh-virtual-machine,43723,1676866324673-splitting is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:115)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2783)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1047)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:626)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:845)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:788)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2455)
2023-02-24 00:24:48,423 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/MasterProcWALs/state-00000000000000000003.log is closed by DFSClient_NONMAPREDUCE_1075336992_1
2023-02-24 00:25:18,197 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 63 Total time for transactions(ms): 56 Number of transactions batched in Syncs: 21 Number of syncs: 42 SyncTimes(ms): 61 
2023-02-24 00:25:22,652 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021, replicas=127.0.0.1:50010 for /hbase/MasterProcWALs/state-00000000000000000004.log
2023-02-24 00:25:22,719 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/MasterProcWALs/state-00000000000000000004.log for DFSClient_NONMAPREDUCE_1075336992_1
2023-02-24 00:25:22,943 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022, replicas=127.0.0.1:50010 for /hbase/.tmp/data/default/webtable/.tmp/.tableinfo.0000000001
2023-02-24 00:25:22,969 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/default/webtable/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_1075336992_1
2023-02-24 00:25:22,998 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023, replicas=127.0.0.1:50010 for /hbase/.tmp/data/default/webtable/03b98accee9693acadf916bb35da40ec/.regioninfo
2023-02-24 00:25:23,015 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/default/webtable/03b98accee9693acadf916bb35da40ec/.regioninfo is closed by DFSClient_NONMAPREDUCE_1075336992_1
2023-02-24 00:25:23,379 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/default/webtable/03b98accee9693acadf916bb35da40ec/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_1075336992_1
2023-02-24 00:27:14,539 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-24 00:27:14,566 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-24 01:57:22,533 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-24 01:57:22,548 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-24 01:57:22,558 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2023-02-24 01:57:23,026 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-24 01:57:23,458 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-24 01:57:23,458 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2023-02-24 01:57:23,515 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2023-02-24 01:57:23,520 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2023-02-24 01:57:23,989 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-24 01:57:24,029 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2023-02-24 01:57:24,135 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-24 01:57:24,148 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-24 01:57:24,164 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2023-02-24 01:57:24,173 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-24 01:57:24,178 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-02-24 01:57:24,178 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-24 01:57:24,179 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-24 01:57:24,510 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2023-02-24 01:57:24,513 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-02-24 01:57:24,581 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2023-02-24 01:57:24,581 INFO org.mortbay.log: jetty-6.1.26
2023-02-24 01:57:24,840 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2023-02-24 01:57:24,899 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 01:57:24,900 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 01:57:24,901 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-24 01:57:24,901 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-24 01:57:24,909 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 01:57:24,909 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 01:57:25,009 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2023-02-24 01:57:25,056 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2023-02-24 01:57:25,060 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2023-02-24 01:57:25,071 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2023-02-24 01:57:25,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2023-02-24 01:57:25,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2023-02-24 01:57:25,203 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-02-24 01:57:25,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Feb 24 01:57:25
2023-02-24 01:57:25,207 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2023-02-24 01:57:25,207 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-24 01:57:25,210 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2023-02-24 01:57:25,210 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2023-02-24 01:57:25,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2023-02-24 01:57:25,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2023-02-24 01:57:25,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2023-02-24 01:57:25,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2023-02-24 01:57:25,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2023-02-24 01:57:25,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2023-02-24 01:57:25,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2023-02-24 01:57:25,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2023-02-24 01:57:25,343 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ganesh (auth:SIMPLE)
2023-02-24 01:57:25,343 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2023-02-24 01:57:25,343 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2023-02-24 01:57:25,344 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2023-02-24 01:57:25,346 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2023-02-24 01:57:25,530 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2023-02-24 01:57:25,530 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-24 01:57:25,530 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2023-02-24 01:57:25,530 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2023-02-24 01:57:25,651 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2023-02-24 01:57:25,651 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2023-02-24 01:57:25,652 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2023-02-24 01:57:25,679 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2023-02-24 01:57:25,679 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-24 01:57:25,679 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2023-02-24 01:57:25,679 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2023-02-24 01:57:25,682 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2023-02-24 01:57:25,682 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2023-02-24 01:57:25,682 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2023-02-24 01:57:25,687 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-02-24 01:57:25,687 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2023-02-24 01:57:25,687 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-02-24 01:57:25,692 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2023-02-24 01:57:25,692 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-02-24 01:57:25,699 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2023-02-24 01:57:25,699 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-24 01:57:25,699 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2023-02-24 01:57:25,699 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2023-02-24 01:57:25,718 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ganesh/Desktop/HADOOP_F1/in_use.lock acquired by nodename 2971@ganesh-virtual-machine
2023-02-24 01:57:25,983 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ganesh/Desktop/HADOOP_F1/current
2023-02-24 01:57:26,103 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000147 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000147-0000000000000000236
2023-02-24 01:57:26,301 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000146, cpktTxId=0000000000000000146)
2023-02-24 01:57:26,379 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 46 INodes.
2023-02-24 01:57:26,471 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2023-02-24 01:57:26,472 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 146 from /home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000146
2023-02-24 01:57:26,472 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7b8233cd expecting start txid #147
2023-02-24 01:57:26,472 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000147-0000000000000000236
2023-02-24 01:57:26,474 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000147-0000000000000000236' to transaction ID 147
2023-02-24 01:57:26,612 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000147-0000000000000000236 of size 1048576 edits # 90 loaded in 0 seconds
2023-02-24 01:57:26,612 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2023-02-24 01:57:26,613 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2023-02-24 01:57:26,625 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000236 using no compression
2023-02-24 01:57:26,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000236 of size 5202 bytes saved in 0 seconds.
2023-02-24 01:57:26,734 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 146
2023-02-24 01:57:26,735 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000144, cpktTxId=0000000000000000144)
2023-02-24 01:57:26,764 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 237
2023-02-24 01:57:26,932 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem write lock held for 1228 ms via
java.lang.Thread.getStackTrace(Thread.java:1564)
org.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:1032)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:233)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.writeUnlock(FSNamesystem.java:1537)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1041)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:691)
org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:634)
org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:695)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:898)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:877)
org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1603)
org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1671)
	Number of suppressed write-lock reports: 0
	Longest write-lock held interval: 1228
2023-02-24 01:57:26,932 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2023-02-24 01:57:26,932 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1229 msecs
2023-02-24 01:57:27,326 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2023-02-24 01:57:27,338 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-24 01:57:27,358 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2023-02-24 01:57:27,489 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2023-02-24 01:57:27,492 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 01:57:27,518 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 3
2023-02-24 01:57:27,519 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 12 blocks to reach the threshold 0.9990 of total blocks 13.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2023-02-24 01:57:27,601 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-24 01:57:27,630 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2023-02-24 01:57:27,641 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2023-02-24 01:57:27,648 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2023-02-24 01:57:27,648 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2023-02-24 01:57:27,681 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 33 milliseconds
name space=59
storage space=402659700
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2023-02-24 01:57:27,737 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-02-24 01:57:35,154 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519) storage 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-24 01:57:35,158 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2023-02-24 01:57:35,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 4e10373a-8afa-4846-a4e7-48202a2a517c (127.0.0.1:50010).
2023-02-24 01:57:35,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 for DN 127.0.0.1:50010
2023-02-24 01:57:35,908 INFO BlockStateChange: BLOCK* processReport 0x758fabd28bfa4d79: Processing first storage report for DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 from datanode 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-24 01:57:35,951 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 12 has reached the threshold 0.9990 of total blocks 13. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2023-02-24 01:57:35,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2023-02-24 01:57:35,968 INFO BlockStateChange: BLOCK* processReport 0x758fabd28bfa4d79: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 16, hasStaleStorage: false, processing time: 54 msecs, invalidatedBlocks: 0
2023-02-24 01:57:35,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 16
2023-02-24 01:57:35,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2023-02-24 01:57:35,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 9
2023-02-24 01:57:35,977 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2023-02-24 01:57:35,977 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 3
2023-02-24 01:57:35,977 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2023-02-24 01:57:55,976 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 13 has reached the threshold 0.9990 of total blocks 13. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2023-02-24 01:58:05,978 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 40 secs
2023-02-24 01:58:05,979 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2023-02-24 01:58:05,979 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2023-02-24 01:58:05,979 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 9 blocks
2023-02-24 02:03:08,720 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-24 02:03:08,727 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-24 02:04:50,105 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-24 02:04:50,115 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-24 02:04:50,123 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2023-02-24 02:04:50,527 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-24 02:04:50,663 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-24 02:04:50,664 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2023-02-24 02:04:50,689 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2023-02-24 02:04:50,693 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2023-02-24 02:04:50,967 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-24 02:04:50,977 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2023-02-24 02:04:51,039 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-24 02:04:51,049 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-24 02:04:51,056 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2023-02-24 02:04:51,062 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-24 02:04:51,065 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-02-24 02:04:51,065 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-24 02:04:51,065 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-24 02:04:51,229 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2023-02-24 02:04:51,232 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-02-24 02:04:51,250 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2023-02-24 02:04:51,250 INFO org.mortbay.log: jetty-6.1.26
2023-02-24 02:04:51,409 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2023-02-24 02:04:51,443 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 02:04:51,443 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 02:04:51,444 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-24 02:04:51,444 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-24 02:04:51,450 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 02:04:51,450 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 02:04:51,499 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2023-02-24 02:04:51,511 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2023-02-24 02:04:51,513 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2023-02-24 02:04:51,516 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2023-02-24 02:04:51,571 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2023-02-24 02:04:51,572 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2023-02-24 02:04:51,574 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-02-24 02:04:51,574 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Feb 24 02:04:51
2023-02-24 02:04:51,576 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2023-02-24 02:04:51,576 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-24 02:04:51,577 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2023-02-24 02:04:51,578 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2023-02-24 02:04:51,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2023-02-24 02:04:51,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2023-02-24 02:04:51,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2023-02-24 02:04:51,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2023-02-24 02:04:51,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2023-02-24 02:04:51,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2023-02-24 02:04:51,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2023-02-24 02:04:51,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2023-02-24 02:04:51,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ganesh (auth:SIMPLE)
2023-02-24 02:04:51,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2023-02-24 02:04:51,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2023-02-24 02:04:51,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2023-02-24 02:04:51,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2023-02-24 02:04:51,707 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2023-02-24 02:04:51,707 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-24 02:04:51,707 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2023-02-24 02:04:51,707 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2023-02-24 02:04:51,734 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2023-02-24 02:04:51,734 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2023-02-24 02:04:51,734 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2023-02-24 02:04:51,744 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2023-02-24 02:04:51,744 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-24 02:04:51,744 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2023-02-24 02:04:51,744 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2023-02-24 02:04:51,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2023-02-24 02:04:51,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2023-02-24 02:04:51,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2023-02-24 02:04:51,752 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-02-24 02:04:51,752 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2023-02-24 02:04:51,752 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-02-24 02:04:51,756 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2023-02-24 02:04:51,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-02-24 02:04:51,760 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2023-02-24 02:04:51,760 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-24 02:04:51,760 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2023-02-24 02:04:51,760 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2023-02-24 02:04:51,772 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ganesh/Desktop/HADOOP_F1/in_use.lock acquired by nodename 5123@ganesh-virtual-machine
2023-02-24 02:04:51,891 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ganesh/Desktop/HADOOP_F1/current
2023-02-24 02:04:51,930 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000237 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000237-0000000000000000237
2023-02-24 02:04:51,976 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000236, cpktTxId=0000000000000000236)
2023-02-24 02:04:52,040 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 59 INodes.
2023-02-24 02:04:52,121 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2023-02-24 02:04:52,121 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 236 from /home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000236
2023-02-24 02:04:52,122 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7b8233cd expecting start txid #237
2023-02-24 02:04:52,122 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000237-0000000000000000237
2023-02-24 02:04:52,125 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000237-0000000000000000237' to transaction ID 237
2023-02-24 02:04:52,140 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000237-0000000000000000237 of size 1048576 edits # 1 loaded in 0 seconds
2023-02-24 02:04:52,140 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-02-24 02:04:52,141 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 238
2023-02-24 02:04:52,272 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2023-02-24 02:04:52,273 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 509 msecs
2023-02-24 02:04:52,531 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2023-02-24 02:04:52,539 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-24 02:04:52,555 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2023-02-24 02:04:52,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2023-02-24 02:04:52,663 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 02:04:52,686 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 3
2023-02-24 02:04:52,687 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 12 blocks to reach the threshold 0.9990 of total blocks 13.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2023-02-24 02:04:52,768 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-24 02:04:52,769 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2023-02-24 02:04:52,774 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2023-02-24 02:04:52,778 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2023-02-24 02:04:52,779 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2023-02-24 02:04:52,807 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 28 milliseconds
name space=59
storage space=402659700
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2023-02-24 02:04:52,813 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-02-24 02:05:00,454 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519) storage 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-24 02:05:00,455 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2023-02-24 02:05:00,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 4e10373a-8afa-4846-a4e7-48202a2a517c (127.0.0.1:50010).
2023-02-24 02:05:00,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 for DN 127.0.0.1:50010
2023-02-24 02:05:00,694 INFO BlockStateChange: BLOCK* processReport 0xd22fb77fd75b203: Processing first storage report for DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 from datanode 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-24 02:05:00,711 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 12 has reached the threshold 0.9990 of total blocks 13. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2023-02-24 02:05:00,711 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2023-02-24 02:05:00,719 INFO BlockStateChange: BLOCK* processReport 0xd22fb77fd75b203: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 16, hasStaleStorage: false, processing time: 25 msecs, invalidatedBlocks: 0
2023-02-24 02:05:00,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 16
2023-02-24 02:05:00,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2023-02-24 02:05:00,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 9
2023-02-24 02:05:00,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2023-02-24 02:05:00,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 3
2023-02-24 02:05:00,734 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 15 msec
2023-02-24 02:05:20,735 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 13 has reached the threshold 0.9990 of total blocks 13. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2023-02-24 02:05:30,747 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 39 secs
2023-02-24 02:05:30,747 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2023-02-24 02:05:30,747 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2023-02-24 02:05:30,747 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 9 blocks
2023-02-24 02:06:04,490 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 34 Number of transactions batched in Syncs: 237 Number of syncs: 2 SyncTimes(ms): 5 
2023-02-24 02:06:44,338 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1097ms
No GCs detected
2023-02-24 02:19:17,264 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1122ms
No GCs detected
2023-02-24 02:23:56,456 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1071ms
No GCs detected
2023-02-24 02:27:58,265 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-24 02:27:58,270 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-24 18:46:01,272 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-24 18:46:01,324 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-24 18:46:01,334 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2023-02-24 18:46:01,878 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-24 18:46:02,148 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-24 18:46:02,149 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2023-02-24 18:46:02,185 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2023-02-24 18:46:02,189 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2023-02-24 18:46:02,687 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-24 18:46:02,719 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2023-02-24 18:46:02,819 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-24 18:46:02,830 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-24 18:46:02,845 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2023-02-24 18:46:02,854 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-24 18:46:02,857 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-02-24 18:46:02,858 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-24 18:46:02,858 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-24 18:46:03,128 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2023-02-24 18:46:03,131 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-02-24 18:46:03,183 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2023-02-24 18:46:03,183 INFO org.mortbay.log: jetty-6.1.26
2023-02-24 18:46:03,452 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2023-02-24 18:46:03,509 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 18:46:03,509 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 18:46:03,510 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-24 18:46:03,510 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-24 18:46:03,516 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 18:46:03,517 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 18:46:03,601 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2023-02-24 18:46:03,625 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2023-02-24 18:46:03,627 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2023-02-24 18:46:03,632 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2023-02-24 18:46:03,737 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2023-02-24 18:46:03,737 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2023-02-24 18:46:03,740 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-02-24 18:46:03,740 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Feb 24 18:46:03
2023-02-24 18:46:03,744 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2023-02-24 18:46:03,744 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-24 18:46:03,747 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2023-02-24 18:46:03,747 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2023-02-24 18:46:03,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2023-02-24 18:46:03,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2023-02-24 18:46:03,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2023-02-24 18:46:03,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2023-02-24 18:46:03,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2023-02-24 18:46:03,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2023-02-24 18:46:03,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2023-02-24 18:46:03,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2023-02-24 18:46:03,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ganesh (auth:SIMPLE)
2023-02-24 18:46:03,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2023-02-24 18:46:03,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2023-02-24 18:46:03,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2023-02-24 18:46:03,904 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2023-02-24 18:46:04,163 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2023-02-24 18:46:04,163 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-24 18:46:04,164 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2023-02-24 18:46:04,164 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2023-02-24 18:46:04,306 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2023-02-24 18:46:04,306 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2023-02-24 18:46:04,306 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2023-02-24 18:46:04,321 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2023-02-24 18:46:04,321 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-24 18:46:04,322 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2023-02-24 18:46:04,322 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2023-02-24 18:46:04,327 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2023-02-24 18:46:04,327 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2023-02-24 18:46:04,327 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2023-02-24 18:46:04,334 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-02-24 18:46:04,334 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2023-02-24 18:46:04,334 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-02-24 18:46:04,340 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2023-02-24 18:46:04,340 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-02-24 18:46:04,345 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2023-02-24 18:46:04,345 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-24 18:46:04,345 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2023-02-24 18:46:04,345 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2023-02-24 18:46:04,505 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ganesh/Desktop/HADOOP_F1/in_use.lock acquired by nodename 3301@ganesh-virtual-machine
2023-02-24 18:46:04,542 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ganesh/Desktop/HADOOP_F1/current
2023-02-24 18:46:04,661 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000238 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000238-0000000000000000239
2023-02-24 18:46:04,892 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000236, cpktTxId=0000000000000000236)
2023-02-24 18:46:05,081 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 59 INodes.
2023-02-24 18:46:05,180 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2023-02-24 18:46:05,180 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 236 from /home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000236
2023-02-24 18:46:05,180 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@72758afa expecting start txid #237
2023-02-24 18:46:05,181 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000237-0000000000000000237
2023-02-24 18:46:05,183 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000237-0000000000000000237' to transaction ID 237
2023-02-24 18:46:05,216 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000237-0000000000000000237 of size 1048576 edits # 1 loaded in 0 seconds
2023-02-24 18:46:05,217 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@fb9c7aa expecting start txid #238
2023-02-24 18:46:05,217 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000238-0000000000000000239
2023-02-24 18:46:05,217 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000238-0000000000000000239' to transaction ID 237
2023-02-24 18:46:05,249 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000238-0000000000000000239 of size 1048576 edits # 2 loaded in 0 seconds
2023-02-24 18:46:05,249 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2023-02-24 18:46:05,249 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2023-02-24 18:46:05,260 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000239 using no compression
2023-02-24 18:46:05,358 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000239 of size 5259 bytes saved in 0 seconds.
2023-02-24 18:46:05,373 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 236
2023-02-24 18:46:05,374 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000146, cpktTxId=0000000000000000146)
2023-02-24 18:46:05,403 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 240
2023-02-24 18:46:05,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem write lock held for 1204 ms via
java.lang.Thread.getStackTrace(Thread.java:1564)
org.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:1032)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:233)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.writeUnlock(FSNamesystem.java:1537)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1041)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:691)
org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:634)
org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:695)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:898)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:877)
org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1603)
org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1671)
	Number of suppressed write-lock reports: 0
	Longest write-lock held interval: 1204
2023-02-24 18:46:05,557 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2023-02-24 18:46:05,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1204 msecs
2023-02-24 18:46:05,942 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2023-02-24 18:46:05,952 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-24 18:46:05,979 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2023-02-24 18:46:06,114 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2023-02-24 18:46:06,116 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-24 18:46:06,148 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 3
2023-02-24 18:46:06,149 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 12 blocks to reach the threshold 0.9990 of total blocks 13.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2023-02-24 18:46:06,226 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-24 18:46:06,228 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2023-02-24 18:46:06,237 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2023-02-24 18:46:06,243 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2023-02-24 18:46:06,243 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2023-02-24 18:46:06,258 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 14 milliseconds
name space=60
storage space=402659700
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2023-02-24 18:46:06,271 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-02-24 18:46:14,802 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519) storage 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-24 18:46:14,804 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2023-02-24 18:46:14,805 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 4e10373a-8afa-4846-a4e7-48202a2a517c (127.0.0.1:50010).
2023-02-24 18:46:15,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 for DN 127.0.0.1:50010
2023-02-24 18:46:15,171 INFO BlockStateChange: BLOCK* processReport 0xe0aa3c0a99fbec67: Processing first storage report for DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 from datanode 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-24 18:46:15,183 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 12 has reached the threshold 0.9990 of total blocks 13. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2023-02-24 18:46:15,183 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2023-02-24 18:46:15,190 INFO BlockStateChange: BLOCK* processReport 0xe0aa3c0a99fbec67: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 16, hasStaleStorage: false, processing time: 19 msecs, invalidatedBlocks: 0
2023-02-24 18:46:15,202 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 16
2023-02-24 18:46:15,202 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2023-02-24 18:46:15,202 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 9
2023-02-24 18:46:15,202 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2023-02-24 18:46:15,202 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 3
2023-02-24 18:46:15,206 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2023-02-24 18:46:35,223 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 13 has reached the threshold 0.9990 of total blocks 13. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2023-02-24 18:46:45,225 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 41 secs
2023-02-24 18:46:45,226 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2023-02-24 18:46:45,226 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2023-02-24 18:46:45,226 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 9 blocks
2023-02-24 18:52:08,989 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1068ms
No GCs detected
2023-02-24 19:14:41,679 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 239 Number of syncs: 2 SyncTimes(ms): 18 
2023-02-24 19:14:41,806 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024, replicas=127.0.0.1:50010 for /mydir/LICENSE.txt._COPYING_
2023-02-24 19:14:42,094 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741848_1024 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /mydir/LICENSE.txt._COPYING_
2023-02-24 19:14:42,094 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2023-02-24 19:14:42,503 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mydir/LICENSE.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_468881648_1
2023-02-24 19:20:58,298 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 10 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 240 Number of syncs: 7 SyncTimes(ms): 24 
2023-02-24 19:21:00,045 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025, replicas=127.0.0.1:50010 for /mydir/out/_temporary/0/_temporary/attempt_local1148899396_0001_r_000000_0/part-r-00000
2023-02-24 19:21:00,147 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mydir/out/_temporary/0/_temporary/attempt_local1148899396_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_-1200741307_1
2023-02-24 19:21:00,400 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mydir/out/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1200741307_1
2023-02-24 19:21:31,021 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-24 19:21:31,021 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-24 19:21:31,021 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 240, 261
2023-02-24 19:21:31,022 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=262 lastSyncedTxid=261 mostRecentTxid=262
2023-02-24 19:21:31,023 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=262 lastSyncedTxid=262 mostRecentTxid=262
2023-02-24 19:21:31,024 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 23 Total time for transactions(ms): 26 Number of transactions batched in Syncs: 246 Number of syncs: 17 SyncTimes(ms): 49 
2023-02-24 19:21:31,040 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000240 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000240-0000000000000000262
2023-02-24 19:21:31,044 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 263
2023-02-24 19:21:33,816 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 1000.00 KB/s
2023-02-24 19:21:33,816 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000262 size 5527 bytes.
2023-02-24 19:21:33,831 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 239
2023-02-24 19:21:33,831 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000236, cpktTxId=0000000000000000236)
2023-02-24 19:46:05,564 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: [Lease.  Holder: DFSClient_NONMAPREDUCE_1075336992_1, pending creates: 3] has expired hard limit
2023-02-24 19:46:05,565 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_1075336992_1, pending creates: 3], src=/hbase/MasterProcWALs/state-00000000000000000004.log
2023-02-24 19:46:05,570 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /hbase/MasterProcWALs/state-00000000000000000004.log has not been closed. Lease recovery is in progress. RecoveryId = 1026 for block blk_1073741845_1021
2023-02-24 19:46:05,571 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_1075336992_1, pending creates: 2], src=/hbase/WALs/ganesh-virtual-machine,34387,1677219855819/ganesh-virtual-machine%2C34387%2C1677219855819.default.1677219861214
2023-02-24 19:46:05,571 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /hbase/WALs/ganesh-virtual-machine,34387,1677219855819/ganesh-virtual-machine%2C34387%2C1677219855819.default.1677219861214 has not been closed. Lease recovery is in progress. RecoveryId = 1027 for block blk_1073741840_1016
2023-02-24 19:46:05,571 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_1075336992_1, pending creates: 1], src=/hbase/WALs/ganesh-virtual-machine,34387,1677219855819/ganesh-virtual-machine%2C34387%2C1677219855819..meta.1677219863672.meta
2023-02-24 19:46:05,571 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /hbase/WALs/ganesh-virtual-machine,34387,1677219855819/ganesh-virtual-machine%2C34387%2C1677219855819..meta.1677219863672.meta has not been closed. Lease recovery is in progress. RecoveryId = 1028 for block blk_1073741841_1017
2023-02-24 19:46:05,571 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 7 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 11 
2023-02-24 19:46:06,587 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-133797978-127.0.1.1-1675826040519:blk_1073741845_1021, newgenerationstamp=1026, newlength=5059, newtargets=[127.0.0.1:50010], closeFile=true, deleteBlock=false)
2023-02-24 19:46:06,593 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-133797978-127.0.1.1-1675826040519:blk_1073741845_1021, file=/hbase/MasterProcWALs/state-00000000000000000004.log, newgenerationstamp=1026, newlength=5059, newtargets=[127.0.0.1:50010]) successful
2023-02-24 19:46:06,597 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-133797978-127.0.1.1-1675826040519:blk_1073741840_1016, newgenerationstamp=1027, newlength=872, newtargets=[127.0.0.1:50010], closeFile=true, deleteBlock=false)
2023-02-24 19:46:06,599 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-133797978-127.0.1.1-1675826040519:blk_1073741840_1016, file=/hbase/WALs/ganesh-virtual-machine,34387,1677219855819/ganesh-virtual-machine%2C34387%2C1677219855819.default.1677219861214, newgenerationstamp=1027, newlength=872, newtargets=[127.0.0.1:50010]) successful
2023-02-24 19:46:06,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-133797978-127.0.1.1-1675826040519:blk_1073741841_1017, newgenerationstamp=1028, newlength=1664, newtargets=[127.0.0.1:50010], closeFile=true, deleteBlock=false)
2023-02-24 19:46:06,602 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-133797978-127.0.1.1-1675826040519:blk_1073741841_1017, file=/hbase/WALs/ganesh-virtual-machine,34387,1677219855819/ganesh-virtual-machine%2C34387%2C1677219855819..meta.1677219863672.meta, newgenerationstamp=1028, newlength=1664, newtargets=[127.0.0.1:50010]) successful
2023-02-24 20:36:59,257 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-24 20:36:59,257 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-24 20:36:59,257 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 263, 272
2023-02-24 20:36:59,258 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=273 lastSyncedTxid=272 mostRecentTxid=273
2023-02-24 20:36:59,258 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 5 Number of syncs: 6 SyncTimes(ms): 15 
2023-02-24 20:36:59,259 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=273 lastSyncedTxid=273 mostRecentTxid=273
2023-02-24 20:36:59,259 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 5 Number of syncs: 7 SyncTimes(ms): 16 
2023-02-24 20:36:59,260 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000263 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000263-0000000000000000273
2023-02-24 20:36:59,260 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 274
2023-02-24 20:36:59,353 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2023-02-24 20:36:59,354 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000273 size 5051 bytes.
2023-02-24 20:36:59,364 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 262
2023-02-24 20:36:59,364 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000239, cpktTxId=0000000000000000239)
2023-02-24 20:56:34,722 INFO BlockStateChange: BLOCK* processReport 0xe0aa3c0a99fbec68: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 18, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2023-02-24 21:45:02,647 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 50467ms
No GCs detected
2023-02-24 22:49:14,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-24 22:49:14,307 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-24 22:49:14,307 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 274, 274
2023-02-24 22:49:14,308 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=275 lastSyncedTxid=274 mostRecentTxid=275
2023-02-24 22:49:14,308 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 12 
2023-02-24 22:49:14,312 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=275 lastSyncedTxid=275 mostRecentTxid=275
2023-02-24 22:49:14,312 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 16 
2023-02-24 22:49:14,313 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000274 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000274-0000000000000000275
2023-02-24 22:49:14,314 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 276
2023-02-24 22:49:14,391 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2000.00 KB/s
2023-02-24 22:49:14,391 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000275 size 5051 bytes.
2023-02-24 22:49:14,397 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 273
2023-02-24 22:49:14,397 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000262, cpktTxId=0000000000000000262)
2023-02-24 23:35:18,926 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1056ms
No GCs detected
2023-02-24 23:58:05,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-24 23:58:05,910 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-24 23:58:05,910 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 276, 276
2023-02-24 23:58:05,910 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=277 lastSyncedTxid=276 mostRecentTxid=277
2023-02-24 23:58:05,910 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2023-02-24 23:58:05,912 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=277 lastSyncedTxid=277 mostRecentTxid=277
2023-02-24 23:58:05,912 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 9 
2023-02-24 23:58:05,953 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000276 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000276-0000000000000000277
2023-02-24 23:58:05,956 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 278
2023-02-24 23:58:06,057 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2000.00 KB/s
2023-02-24 23:58:06,057 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000277 size 5051 bytes.
2023-02-24 23:58:06,060 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 275
2023-02-24 23:58:06,060 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000273, cpktTxId=0000000000000000273)
2023-02-25 00:54:50,390 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 14185ms
No GCs detected
2023-02-25 01:37:12,468 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-25 01:37:12,608 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-25 15:11:12,624 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-25 15:11:12,642 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-25 15:11:12,653 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2023-02-25 15:11:13,250 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-25 15:11:13,617 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-25 15:11:13,617 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2023-02-25 15:11:13,660 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2023-02-25 15:11:13,666 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2023-02-25 15:11:14,516 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-25 15:11:14,589 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2023-02-25 15:11:14,716 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-25 15:11:14,730 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-25 15:11:14,746 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2023-02-25 15:11:14,759 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-25 15:11:14,764 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-02-25 15:11:14,764 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-25 15:11:14,765 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-25 15:11:15,033 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2023-02-25 15:11:15,035 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-02-25 15:11:15,069 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2023-02-25 15:11:15,069 INFO org.mortbay.log: jetty-6.1.26
2023-02-25 15:11:15,274 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2023-02-25 15:11:15,334 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-25 15:11:15,337 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-25 15:11:15,337 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-25 15:11:15,337 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2023-02-25 15:11:15,343 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-25 15:11:15,343 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-25 15:11:15,411 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2023-02-25 15:11:15,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2023-02-25 15:11:15,428 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2023-02-25 15:11:15,430 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2023-02-25 15:11:15,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2023-02-25 15:11:15,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2023-02-25 15:11:15,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-02-25 15:11:15,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Feb 25 15:11:15
2023-02-25 15:11:15,629 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2023-02-25 15:11:15,629 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-25 15:11:15,636 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2023-02-25 15:11:15,636 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2023-02-25 15:11:15,705 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2023-02-25 15:11:15,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2023-02-25 15:11:15,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2023-02-25 15:11:15,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2023-02-25 15:11:15,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2023-02-25 15:11:15,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2023-02-25 15:11:15,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2023-02-25 15:11:15,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2023-02-25 15:11:15,746 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ganesh (auth:SIMPLE)
2023-02-25 15:11:15,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2023-02-25 15:11:15,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2023-02-25 15:11:15,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2023-02-25 15:11:15,752 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2023-02-25 15:11:15,951 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2023-02-25 15:11:15,951 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-25 15:11:15,951 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2023-02-25 15:11:15,951 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2023-02-25 15:11:15,952 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2023-02-25 15:11:15,952 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2023-02-25 15:11:15,952 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2023-02-25 15:11:15,969 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2023-02-25 15:11:15,969 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-25 15:11:15,971 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2023-02-25 15:11:15,971 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2023-02-25 15:11:15,976 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2023-02-25 15:11:15,976 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2023-02-25 15:11:15,976 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2023-02-25 15:11:15,986 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-02-25 15:11:15,986 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2023-02-25 15:11:15,986 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-02-25 15:11:16,000 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2023-02-25 15:11:16,001 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-02-25 15:11:16,006 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2023-02-25 15:11:16,006 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2023-02-25 15:11:16,006 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2023-02-25 15:11:16,006 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2023-02-25 15:11:16,025 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ganesh/Desktop/HADOOP_F1/in_use.lock acquired by nodename 3827@ganesh-virtual-machine
2023-02-25 15:11:16,261 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ganesh/Desktop/HADOOP_F1/current
2023-02-25 15:11:16,328 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000278 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000278-0000000000000000278
2023-02-25 15:11:16,429 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000277, cpktTxId=0000000000000000277)
2023-02-25 15:11:16,531 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 64 INodes.
2023-02-25 15:11:16,642 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2023-02-25 15:11:16,643 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 277 from /home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000277
2023-02-25 15:11:16,643 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7b8233cd expecting start txid #278
2023-02-25 15:11:16,643 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000278-0000000000000000278
2023-02-25 15:11:16,645 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000278-0000000000000000278' to transaction ID 278
2023-02-25 15:11:16,668 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000278-0000000000000000278 of size 1048576 edits # 1 loaded in 0 seconds
2023-02-25 15:11:16,669 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2023-02-25 15:11:16,669 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2023-02-25 15:11:16,679 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000278 using no compression
2023-02-25 15:11:16,771 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/ganesh/Desktop/HADOOP_F1/current/fsimage.ckpt_0000000000000000278 of size 5051 bytes saved in 0 seconds.
2023-02-25 15:11:16,790 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 277
2023-02-25 15:11:16,791 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000275, cpktTxId=0000000000000000275)
2023-02-25 15:11:16,814 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 279
2023-02-25 15:11:16,957 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2023-02-25 15:11:16,957 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 946 msecs
2023-02-25 15:11:17,389 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2023-02-25 15:11:17,405 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-25 15:11:17,440 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2023-02-25 15:11:17,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2023-02-25 15:11:17,665 WARN org.apache.hadoop.hdfs.server.common.Util: Path /home/ganesh/Desktop/HADOOP_F1 should be specified as a URI in configuration files. Please update hdfs configuration.
2023-02-25 15:11:17,690 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2023-02-25 15:11:17,691 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 17 blocks to reach the threshold 0.9990 of total blocks 18.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2023-02-25 15:11:17,793 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-25 15:11:17,800 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2023-02-25 15:11:17,814 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2023-02-25 15:11:17,823 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2023-02-25 15:11:17,823 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2023-02-25 15:11:17,848 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 25 milliseconds
name space=64
storage space=138991
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2023-02-25 15:11:17,860 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-02-25 15:11:28,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519) storage 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-25 15:11:28,395 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2023-02-25 15:11:28,405 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 4e10373a-8afa-4846-a4e7-48202a2a517c (127.0.0.1:50010).
2023-02-25 15:11:28,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 for DN 127.0.0.1:50010
2023-02-25 15:11:28,828 INFO BlockStateChange: BLOCK* processReport 0x26c2291b5bf1aa8f: Processing first storage report for DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 from datanode 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-25 15:11:28,837 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 17 has reached the threshold 0.9990 of total blocks 18. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2023-02-25 15:11:28,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2023-02-25 15:11:28,849 INFO BlockStateChange: BLOCK* processReport 0x26c2291b5bf1aa8f: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 18, hasStaleStorage: false, processing time: 21 msecs, invalidatedBlocks: 0
2023-02-25 15:11:28,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 18
2023-02-25 15:11:28,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2023-02-25 15:11:28,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 9
2023-02-25 15:11:28,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2023-02-25 15:11:28,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2023-02-25 15:11:28,854 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2023-02-25 15:11:48,857 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 18 has reached the threshold 0.9990 of total blocks 18. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2023-02-25 15:11:58,861 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 43 secs
2023-02-25 15:11:58,862 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2023-02-25 15:11:58,862 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2023-02-25 15:11:58,862 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 9 blocks
2023-02-25 15:27:34,475 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26368ms
No GCs detected
2023-02-25 15:34:23,932 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 278 Number of syncs: 2 SyncTimes(ms): 7 
2023-02-25 15:39:05,085 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 278 Number of syncs: 3 SyncTimes(ms): 9 
2023-02-25 15:39:05,239 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1029, replicas=127.0.0.1:50010 for /mydir_1/input.txt._COPYING_
2023-02-25 15:39:05,537 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741850_1029 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /mydir_1/input.txt._COPYING_
2023-02-25 15:39:05,537 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2023-02-25 15:39:05,960 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mydir_1/input.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-172272379_1
2023-02-25 15:48:14,474 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 279 Number of syncs: 8 SyncTimes(ms): 13 
2023-02-25 15:48:15,508 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1030, replicas=127.0.0.1:50010 for /mydir_1/out_1/_temporary/0/_temporary/attempt_local1922356158_0001_r_000000_0/part-r-00000
2023-02-25 15:48:15,553 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mydir_1/out_1/_temporary/0/_temporary/attempt_local1922356158_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_1011363550_1
2023-02-25 15:48:15,609 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mydir_1/out_1/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1011363550_1
2023-02-25 16:03:29,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-25 16:03:29,393 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-25 16:03:29,394 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 279, 301
2023-02-25 16:03:29,395 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=302 lastSyncedTxid=301 mostRecentTxid=302
2023-02-25 16:03:29,395 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 24 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 285 Number of syncs: 17 SyncTimes(ms): 21 
2023-02-25 16:03:29,396 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=302 lastSyncedTxid=302 mostRecentTxid=302
2023-02-25 16:03:29,397 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 24 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 285 Number of syncs: 18 SyncTimes(ms): 22 
2023-02-25 16:03:29,405 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000279 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000279-0000000000000000302
2023-02-25 16:03:29,407 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 303
2023-02-25 16:03:32,176 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1666.67 KB/s
2023-02-25 16:03:32,176 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000302 size 5378 bytes.
2023-02-25 16:03:32,182 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 278
2023-02-25 16:03:32,182 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000277, cpktTxId=0000000000000000277)
2023-02-25 17:03:33,007 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-25 17:03:33,008 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-25 17:03:33,009 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 303, 304
2023-02-25 17:03:33,009 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=305 lastSyncedTxid=303 mostRecentTxid=305
2023-02-25 17:03:33,009 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 18 
2023-02-25 17:03:33,011 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=305 lastSyncedTxid=305 mostRecentTxid=305
2023-02-25 17:03:33,011 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 1 Number of syncs: 3 SyncTimes(ms): 20 
2023-02-25 17:03:33,012 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000303 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000303-0000000000000000305
2023-02-25 17:03:33,013 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 306
2023-02-25 17:03:33,083 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1250.00 KB/s
2023-02-25 17:03:33,083 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000305 size 5378 bytes.
2023-02-25 17:03:33,085 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 302
2023-02-25 17:03:33,086 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000278, cpktTxId=0000000000000000278)
2023-02-25 17:11:47,724 INFO BlockStateChange: BLOCK* processReport 0x26c2291b5bf1aa90: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 20, hasStaleStorage: false, processing time: 8 msecs, invalidatedBlocks: 0
2023-02-25 17:33:38,974 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2023-02-25 17:34:41,579 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 8 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms): 10 
2023-02-25 18:56:42,245 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-25 18:56:42,247 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-25 18:56:42,248 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 306, 314
2023-02-25 18:56:42,248 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=315 lastSyncedTxid=314 mostRecentTxid=315
2023-02-25 18:56:42,248 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 10 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 10 SyncTimes(ms): 11 
2023-02-25 18:56:42,250 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=315 lastSyncedTxid=315 mostRecentTxid=315
2023-02-25 18:56:42,250 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 10 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 11 SyncTimes(ms): 12 
2023-02-25 18:56:42,251 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000306 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000306-0000000000000000315
2023-02-25 18:56:42,252 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 316
2023-02-25 18:56:42,394 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2500.00 KB/s
2023-02-25 18:56:42,394 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000315 size 5499 bytes.
2023-02-25 18:56:42,407 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 305
2023-02-25 18:56:42,408 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000302, cpktTxId=0000000000000000302)
2023-02-25 19:22:14,280 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1044ms
No GCs detected
2023-02-25 19:27:41,572 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1117ms
No GCs detected
2023-02-25 20:42:53,906 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-25 20:42:53,907 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-25 20:42:53,907 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 316, 319
2023-02-25 20:42:53,907 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=320 lastSyncedTxid=316 mostRecentTxid=320
2023-02-25 20:42:53,907 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2023-02-25 20:42:53,947 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=320 lastSyncedTxid=320 mostRecentTxid=320
2023-02-25 20:42:53,947 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 3 Number of syncs: 3 SyncTimes(ms): 9 
2023-02-25 20:42:53,949 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000316 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000316-0000000000000000320
2023-02-25 20:42:53,950 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 321
2023-02-25 20:42:54,084 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2500.00 KB/s
2023-02-25 20:42:54,084 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000320 size 5499 bytes.
2023-02-25 20:42:54,092 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 315
2023-02-25 20:42:54,093 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000305, cpktTxId=0000000000000000305)
2023-02-25 21:16:27,378 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1205ms
No GCs detected
2023-02-25 21:31:50,819 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1437ms
No GCs detected
2023-02-25 21:42:57,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-25 21:42:57,421 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-25 21:42:57,423 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 321, 322
2023-02-25 21:42:57,423 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=323 lastSyncedTxid=321 mostRecentTxid=323
2023-02-25 21:42:57,423 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2023-02-25 21:42:57,425 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=323 lastSyncedTxid=323 mostRecentTxid=323
2023-02-25 21:42:57,425 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 1 Number of syncs: 3 SyncTimes(ms): 9 
2023-02-25 21:42:57,427 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000321 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000321-0000000000000000323
2023-02-25 21:42:57,427 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 324
2023-02-25 21:42:57,565 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2500.00 KB/s
2023-02-25 21:42:57,565 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000323 size 5499 bytes.
2023-02-25 21:42:57,579 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 320
2023-02-25 21:42:57,580 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000315, cpktTxId=0000000000000000315)
2023-02-25 21:48:39,020 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 49704ms
No GCs detected
2023-02-25 22:13:35,785 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1355ms
No GCs detected
2023-02-25 22:14:52,457 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 49621ms
No GCs detected
2023-02-26 13:32:50,581 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4227ms
No GCs detected
2023-02-26 14:04:42,166 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-26 14:04:42,166 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-26 14:04:42,166 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 324, 324
2023-02-26 14:04:42,168 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=325 lastSyncedTxid=324 mostRecentTxid=325
2023-02-26 14:04:42,171 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2023-02-26 14:04:42,176 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=325 lastSyncedTxid=325 mostRecentTxid=325
2023-02-26 14:04:42,176 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 10 
2023-02-26 14:04:42,179 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000324 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000324-0000000000000000325
2023-02-26 14:04:42,180 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 326
2023-02-26 14:04:42,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1250.00 KB/s
2023-02-26 14:04:42,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000325 size 5499 bytes.
2023-02-26 14:04:42,345 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 323
2023-02-26 14:04:42,345 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000320, cpktTxId=0000000000000000320)
2023-02-26 14:14:57,637 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 15 
2023-02-26 14:21:12,688 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 17 
2023-02-26 14:21:12,780 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1031, replicas=127.0.0.1:50010 for /Project_Phase_1/input_data.txt._COPYING_
2023-02-26 14:21:12,879 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741852_1031 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /Project_Phase_1/input_data.txt._COPYING_
2023-02-26 14:21:13,300 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /Project_Phase_1/input_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_1183127592_1
2023-02-26 14:36:17,953 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 2 Number of syncs: 7 SyncTimes(ms): 19 
2023-02-26 14:36:19,068 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1032, replicas=127.0.0.1:50010 for /Project_Phase_1/output_phase_1/_temporary/0/_temporary/attempt_local1435847455_0001_r_000000_0/part-r-00000
2023-02-26 14:36:19,135 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /Project_Phase_1/output_phase_1/_temporary/0/_temporary/attempt_local1435847455_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_1321213996_1
2023-02-26 14:36:19,208 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /Project_Phase_1/output_phase_1/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1321213996_1
2023-02-26 14:47:39,769 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1319ms
No GCs detected
2023-02-26 15:12:13,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-26 15:12:13,427 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-26 15:12:13,427 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 326, 348
2023-02-26 15:12:13,427 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=349 lastSyncedTxid=348 mostRecentTxid=349
2023-02-26 15:12:13,427 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 24 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 8 Number of syncs: 16 SyncTimes(ms): 26 
2023-02-26 15:12:13,428 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=349 lastSyncedTxid=349 mostRecentTxid=349
2023-02-26 15:12:13,428 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 24 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 8 Number of syncs: 17 SyncTimes(ms): 27 
2023-02-26 15:12:13,430 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000326 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000326-0000000000000000349
2023-02-26 15:12:13,430 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 350
2023-02-26 15:12:13,503 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2500.00 KB/s
2023-02-26 15:12:13,504 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000349 size 5848 bytes.
2023-02-26 15:12:13,510 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 325
2023-02-26 15:12:13,510 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000323, cpktTxId=0000000000000000323)
2023-02-26 15:20:30,064 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1302ms
No GCs detected
2023-02-26 15:21:18,119 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22995ms
No GCs detected
2023-02-26 15:59:23,722 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1022ms
No GCs detected
2023-02-26 16:08:00,929 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1016ms
No GCs detected
2023-02-26 16:14:11,443 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-26 16:14:11,443 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-26 16:14:11,443 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 350, 351
2023-02-26 16:14:11,444 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=352 lastSyncedTxid=350 mostRecentTxid=352
2023-02-26 16:14:11,444 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2023-02-26 16:14:11,450 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=352 lastSyncedTxid=352 mostRecentTxid=352
2023-02-26 16:14:11,451 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 1 Number of syncs: 3 SyncTimes(ms): 15 
2023-02-26 16:14:11,461 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000350 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000350-0000000000000000352
2023-02-26 16:14:11,462 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 353
2023-02-26 16:14:11,618 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1666.67 KB/s
2023-02-26 16:14:11,619 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000352 size 5848 bytes.
2023-02-26 16:14:11,627 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 349
2023-02-26 16:14:11,627 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000325, cpktTxId=0000000000000000325)
2023-02-26 16:21:58,120 INFO BlockStateChange: BLOCK* processReport 0x26c2291b5bf1aa91: from storage DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=4e10373a-8afa-4846-a4e7-48202a2a517c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519), blocks: 22, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2023-02-26 17:14:13,240 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-26 17:14:13,240 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-26 17:14:13,240 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 353, 353
2023-02-26 17:14:13,240 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=354 lastSyncedTxid=353 mostRecentTxid=354
2023-02-26 17:14:13,280 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2023-02-26 17:14:13,282 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=354 lastSyncedTxid=354 mostRecentTxid=354
2023-02-26 17:14:13,282 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2023-02-26 17:14:13,283 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000353 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000353-0000000000000000354
2023-02-26 17:14:13,283 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 355
2023-02-26 17:14:13,443 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2500.00 KB/s
2023-02-26 17:14:13,443 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000354 size 5848 bytes.
2023-02-26 17:14:13,449 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 352
2023-02-26 17:14:13,449 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000349, cpktTxId=0000000000000000349)
2023-02-26 17:21:10,984 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1407ms
No GCs detected
2023-02-26 17:21:38,349 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26865ms
No GCs detected
2023-02-26 18:14:40,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2023-02-26 18:14:40,431 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2023-02-26 18:14:40,432 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 355, 355
2023-02-26 18:14:40,433 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=356 lastSyncedTxid=355 mostRecentTxid=356
2023-02-26 18:14:40,434 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2023-02-26 18:14:40,436 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=356 lastSyncedTxid=356 mostRecentTxid=356
2023-02-26 18:14:40,436 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2023-02-26 18:14:40,442 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ganesh/Desktop/HADOOP_F1/current/edits_inprogress_0000000000000000355 -> /home/ganesh/Desktop/HADOOP_F1/current/edits_0000000000000000355-0000000000000000356
2023-02-26 18:14:40,445 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 357
2023-02-26 18:14:40,684 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2500.00 KB/s
2023-02-26 18:14:40,685 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000356 size 5848 bytes.
2023-02-26 18:14:40,698 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 354
2023-02-26 18:14:40,699 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ganesh/Desktop/HADOOP_F1/current/fsimage_0000000000000000352, cpktTxId=0000000000000000352)

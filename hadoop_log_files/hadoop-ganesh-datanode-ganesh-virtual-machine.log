2023-02-07 21:26:28,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-07 21:26:28,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-07 21:26:30,421 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-07 21:26:30,654 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-07 21:26:30,654 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-02-07 21:26:30,702 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-02-07 21:26:30,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ganesh-virtual-machine
2023-02-07 21:26:30,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-02-07 21:26:30,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-02-07 21:26:30,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2023-02-07 21:26:30,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2023-02-07 21:26:31,057 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-07 21:26:31,080 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-07 21:26:31,097 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-02-07 21:26:31,114 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-07 21:26:31,124 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-02-07 21:26:31,126 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-07 21:26:31,126 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-07 21:26:31,208 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40959
2023-02-07 21:26:31,208 INFO org.mortbay.log: jetty-6.1.26
2023-02-07 21:26:31,747 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40959
2023-02-07 21:26:32,765 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-02-07 21:26:32,791 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-07 21:26:32,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ganesh
2023-02-07 21:26:32,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-02-07 21:26:33,196 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-07 21:26:33,288 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-02-07 21:26:33,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-02-07 21:26:33,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-02-07 21:26:33,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-02-07 21:26:33,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2023-02-07 21:26:33,688 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-07 21:26:33,697 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-02-07 21:26:34,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2023-02-07 21:26:34,386 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2023-02-07 21:26:34,400 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on home/ganesh/Desktop/HADOOP_F2/in_use.lock acquired by nodename 8684@ganesh-virtual-machine
2023-02-07 21:26:34,402 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory home/ganesh/Desktop/HADOOP_F2 is not formatted for namespace 648504085. Formatting...
2023-02-07 21:26:34,403 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-3162c58e-bc52-4f4c-9217-6d1817d697b3 for directory home/ganesh/Desktop/HADOOP_F2
2023-02-07 21:26:34,489 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-133797978-127.0.1.1-1675826040519
2023-02-07 21:26:34,489 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519
2023-02-07 21:26:34,489 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519 is not formatted for BP-133797978-127.0.1.1-1675826040519. Formatting ...
2023-02-07 21:26:34,489 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-133797978-127.0.1.1-1675826040519 directory home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current
2023-02-07 21:26:34,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=648504085;bpid=BP-133797978-127.0.1.1-1675826040519;lv=-57;nsInfo=lv=-63;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519;bpid=BP-133797978-127.0.1.1-1675826040519;dnuuid=null
2023-02-07 21:26:34,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-07 21:26:34,670 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-3162c58e-bc52-4f4c-9217-6d1817d697b3
2023-02-07 21:26:34,671 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - home/ganesh/Desktop/HADOOP_F2/current, StorageType: DISK
2023-02-07 21:26:34,676 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-02-07 21:26:34,690 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2023-02-07 21:26:34,690 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-133797978-127.0.1.1-1675826040519
2023-02-07 21:26:34,691 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-07 21:26:34,746 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-133797978-127.0.1.1-1675826040519 on /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 50ms
2023-02-07 21:26:34,746 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-133797978-127.0.1.1-1675826040519: 57ms
2023-02-07 21:26:34,765 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-07 21:26:34,765 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/replicas doesn't exist 
2023-02-07 21:26:34,766 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 2ms
2023-02-07 21:26:34,767 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 17ms
2023-02-07 21:26:34,770 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-133797978-127.0.1.1-1675826040519 on volume home/ganesh/Desktop/HADOOP_F2
2023-02-07 21:26:34,781 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(home/ganesh/Desktop/HADOOP_F2, DS-3162c58e-bc52-4f4c-9217-6d1817d697b3): finished scanning block pool BP-133797978-127.0.1.1-1675826040519
2023-02-07 21:26:34,810 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/7/23 10:53 PM with interval of 21600000ms
2023-02-07 21:26:34,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2023-02-07 21:26:34,918 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(home/ganesh/Desktop/HADOOP_F2, DS-3162c58e-bc52-4f4c-9217-6d1817d697b3): no suitable block pools found to scan.  Waiting 1814399851 ms.
2023-02-07 21:26:35,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 successfully registered with NN
2023-02-07 21:26:35,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-02-07 21:26:35,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5ac794d0482a412d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 36 msec to generate and 94 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-07 21:26:35,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-07 21:32:09,901 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1307ms
No GCs detected
2023-02-07 22:10:41,159 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-07 22:10:41,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-15 22:32:24,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-15 22:32:24,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-15 22:32:25,741 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-15 22:32:25,874 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-15 22:32:25,874 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-02-15 22:32:25,884 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-02-15 22:32:25,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ganesh-virtual-machine
2023-02-15 22:32:25,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-02-15 22:32:25,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-02-15 22:32:25,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2023-02-15 22:32:25,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2023-02-15 22:32:26,103 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-15 22:32:26,117 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-15 22:32:26,125 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-02-15 22:32:26,132 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-15 22:32:26,135 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-02-15 22:32:26,135 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-15 22:32:26,135 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-15 22:32:26,152 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39679
2023-02-15 22:32:26,152 INFO org.mortbay.log: jetty-6.1.26
2023-02-15 22:32:26,378 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39679
2023-02-15 22:32:26,763 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-02-15 22:32:26,777 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-15 22:32:26,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ganesh
2023-02-15 22:32:26,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-02-15 22:32:26,882 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-15 22:32:26,913 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-02-15 22:32:27,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-02-15 22:32:27,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-02-15 22:32:27,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-02-15 22:32:27,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2023-02-15 22:32:27,098 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-15 22:32:27,098 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-02-15 22:32:27,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2023-02-15 22:32:27,506 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2023-02-15 22:32:27,513 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on home/ganesh/Desktop/HADOOP_F2/in_use.lock acquired by nodename 6409@ganesh-virtual-machine
2023-02-15 22:32:27,596 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-133797978-127.0.1.1-1675826040519
2023-02-15 22:32:27,596 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519
2023-02-15 22:32:27,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=648504085;bpid=BP-133797978-127.0.1.1-1675826040519;lv=-57;nsInfo=lv=-63;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519;bpid=BP-133797978-127.0.1.1-1675826040519;dnuuid=4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-15 22:32:27,691 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-3162c58e-bc52-4f4c-9217-6d1817d697b3
2023-02-15 22:32:27,692 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - home/ganesh/Desktop/HADOOP_F2/current, StorageType: DISK
2023-02-15 22:32:27,696 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-02-15 22:32:27,709 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2023-02-15 22:32:27,709 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-133797978-127.0.1.1-1675826040519
2023-02-15 22:32:27,711 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-15 22:32:27,740 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-133797978-127.0.1.1-1675826040519 on /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 28ms
2023-02-15 22:32:27,740 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-133797978-127.0.1.1-1675826040519: 32ms
2023-02-15 22:32:27,743 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-15 22:32:27,743 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/replicas doesn't exist 
2023-02-15 22:32:27,743 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 0ms
2023-02-15 22:32:27,744 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2023-02-15 22:32:27,873 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(home/ganesh/Desktop/HADOOP_F2, DS-3162c58e-bc52-4f4c-9217-6d1817d697b3): no suitable block pools found to scan.  Waiting 1119246896 ms.
2023-02-15 22:32:27,894 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/16/23 3:42 AM with interval of 21600000ms
2023-02-15 22:32:27,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2023-02-15 22:32:28,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 successfully registered with NN
2023-02-15 22:32:28,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-02-15 22:32:28,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5cbefda32fee946e,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 19 msec to generate and 129 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-15 22:32:28,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-15 22:48:29,271 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-15 22:48:29,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-19 21:42:56,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-19 21:42:56,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-19 21:42:57,526 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-19 21:42:57,699 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-19 21:42:57,699 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-02-19 21:42:57,711 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-02-19 21:42:57,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ganesh-virtual-machine
2023-02-19 21:42:57,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-02-19 21:42:57,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-02-19 21:42:57,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2023-02-19 21:42:57,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2023-02-19 21:42:58,078 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-19 21:42:58,089 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-19 21:42:58,098 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-02-19 21:42:58,107 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-19 21:42:58,109 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-02-19 21:42:58,109 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-19 21:42:58,109 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-19 21:42:58,129 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 38151
2023-02-19 21:42:58,129 INFO org.mortbay.log: jetty-6.1.26
2023-02-19 21:42:58,411 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:38151
2023-02-19 21:42:59,047 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-02-19 21:42:59,061 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-19 21:42:59,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ganesh
2023-02-19 21:42:59,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-02-19 21:42:59,154 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-19 21:42:59,193 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-02-19 21:42:59,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-02-19 21:42:59,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-02-19 21:42:59,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-02-19 21:42:59,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2023-02-19 21:42:59,349 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-19 21:42:59,352 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-02-19 21:43:00,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2023-02-19 21:43:00,565 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2023-02-19 21:43:00,594 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on home/ganesh/Desktop/HADOOP_F2/in_use.lock acquired by nodename 3108@ganesh-virtual-machine
2023-02-19 21:43:00,764 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-133797978-127.0.1.1-1675826040519
2023-02-19 21:43:00,764 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519
2023-02-19 21:43:00,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=648504085;bpid=BP-133797978-127.0.1.1-1675826040519;lv=-57;nsInfo=lv=-63;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519;bpid=BP-133797978-127.0.1.1-1675826040519;dnuuid=4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-19 21:43:00,875 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-3162c58e-bc52-4f4c-9217-6d1817d697b3
2023-02-19 21:43:00,875 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - home/ganesh/Desktop/HADOOP_F2/current, StorageType: DISK
2023-02-19 21:43:00,892 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-02-19 21:43:00,937 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2023-02-19 21:43:00,937 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-133797978-127.0.1.1-1675826040519
2023-02-19 21:43:00,940 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-19 21:43:01,028 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-133797978-127.0.1.1-1675826040519 on /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 88ms
2023-02-19 21:43:01,029 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-133797978-127.0.1.1-1675826040519: 92ms
2023-02-19 21:43:01,041 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-19 21:43:01,041 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/replicas doesn't exist 
2023-02-19 21:43:01,041 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 0ms
2023-02-19 21:43:01,043 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 8ms
2023-02-19 21:43:01,206 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(home/ganesh/Desktop/HADOOP_F2, DS-3162c58e-bc52-4f4c-9217-6d1817d697b3): no suitable block pools found to scan.  Waiting 776613563 ms.
2023-02-19 21:43:01,227 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/20/23 2:20 AM with interval of 21600000ms
2023-02-19 21:43:01,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2023-02-19 21:43:01,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 successfully registered with NN
2023-02-19 21:43:01,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-02-19 21:43:02,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x358ed62705febb98,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 177 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-19 21:43:02,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-19 22:03:17,852 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1042ms
No GCs detected
2023-02-19 22:07:55,703 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1074ms
No GCs detected
2023-02-19 22:09:34,469 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1041ms
No GCs detected
2023-02-19 22:11:17,754 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1119ms
No GCs detected
2023-02-19 22:12:05,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741825_1001 src: /127.0.0.1:37548 dest: /127.0.0.1:50010
2023-02-19 22:12:05,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37548, dest: /127.0.0.1:50010, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741825_1001, duration: 73842772
2023-02-19 22:12:05,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2023-02-19 22:12:06,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741826_1002 src: /127.0.0.1:38084 dest: /127.0.0.1:50010
2023-02-19 22:12:06,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38084, dest: /127.0.0.1:50010, bytes: 42, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741826_1002, duration: 9658677
2023-02-19 22:12:06,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2023-02-19 22:12:06,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741827_1003 src: /127.0.0.1:38098 dest: /127.0.0.1:50010
2023-02-19 22:12:06,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38098, dest: /127.0.0.1:50010, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741827_1003, duration: 17002822
2023-02-19 22:12:06,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2023-02-19 22:12:06,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741828_1004 src: /127.0.0.1:38110 dest: /127.0.0.1:50010
2023-02-19 22:12:06,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38110, dest: /127.0.0.1:50010, bytes: 398, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741828_1004, duration: 6770409
2023-02-19 22:12:06,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2023-02-19 22:12:07,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741829_1005 src: /127.0.0.1:38120 dest: /127.0.0.1:50010
2023-02-19 22:12:13,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741830_1006 src: /127.0.0.1:38122 dest: /127.0.0.1:50010
2023-02-19 22:12:13,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741831_1007 src: /127.0.0.1:38124 dest: /127.0.0.1:50010
2023-02-19 22:12:13,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38122, dest: /127.0.0.1:50010, bytes: 275, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741830_1006, duration: 454291658
2023-02-19 22:12:13,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2023-02-19 22:12:13,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741832_1008 src: /127.0.0.1:38136 dest: /127.0.0.1:50010
2023-02-19 22:12:14,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741833_1009 src: /127.0.0.1:38140 dest: /127.0.0.1:50010
2023-02-19 22:12:14,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38140, dest: /127.0.0.1:50010, bytes: 312, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741833_1009, duration: 7401533
2023-02-19 22:12:14,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2023-02-19 22:12:14,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741834_1010 src: /127.0.0.1:38156 dest: /127.0.0.1:50010
2023-02-19 22:12:14,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38156, dest: /127.0.0.1:50010, bytes: 42, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741834_1010, duration: 5347173
2023-02-19 22:12:14,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2023-02-19 22:12:15,955 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1126ms
No GCs detected
2023-02-19 22:12:16,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741835_1011 src: /127.0.0.1:53828 dest: /127.0.0.1:50010
2023-02-19 22:12:16,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38124, dest: /127.0.0.1:50010, bytes: 270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741831_1007, duration: 2628606860
2023-02-19 22:12:16,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2023-02-19 22:12:16,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741836_1012 src: /127.0.0.1:53836 dest: /127.0.0.1:50010
2023-02-19 22:12:16,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38120, dest: /127.0.0.1:50010, bytes: 380, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741829_1005, duration: 8591148052
2023-02-19 22:12:16,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2023-02-19 22:12:16,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741837_1013 src: /127.0.0.1:53850 dest: /127.0.0.1:50010
2023-02-19 22:12:16,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:53828, dest: /127.0.0.1:50010, bytes: 627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741835_1011, duration: 383455337
2023-02-19 22:12:16,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2023-02-19 22:12:16,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741838_1014 src: /127.0.0.1:53862 dest: /127.0.0.1:50010
2023-02-19 22:12:16,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:53836, dest: /127.0.0.1:50010, bytes: 303, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741836_1012, duration: 253590766
2023-02-19 22:12:16,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2023-02-19 22:12:37,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38136, dest: /127.0.0.1:50010, bytes: 3363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741832_1008, duration: 23631553459
2023-02-19 22:12:37,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2023-02-19 22:12:43,132 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741832_1008 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741832 for deletion
2023-02-19 22:12:43,136 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-133797978-127.0.1.1-1675826040519 blk_1073741832_1008 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741832
2023-02-20 00:19:19,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741839_1015 src: /127.0.0.1:50038 dest: /127.0.0.1:50010
2023-02-20 00:19:19,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50038, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741839_1015, duration: 2877794
2023-02-20 00:19:19,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2023-02-20 00:19:19,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:53850, dest: /127.0.0.1:50010, bytes: 91, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741837_1013, duration: 395458449473
2023-02-20 00:19:19,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2023-02-20 00:19:19,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:53862, dest: /127.0.0.1:50010, bytes: 91, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_141585002_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741838_1014, duration: 395318280541
2023-02-20 00:19:19,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2023-02-20 00:46:18,166 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-20 00:46:18,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-21 13:06:35,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-21 13:06:35,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-21 13:06:36,907 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-21 13:06:37,111 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-21 13:06:37,111 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-02-21 13:06:37,125 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-02-21 13:06:37,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ganesh-virtual-machine
2023-02-21 13:06:37,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-02-21 13:06:37,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-02-21 13:06:37,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2023-02-21 13:06:37,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2023-02-21 13:06:37,521 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-21 13:06:37,533 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-21 13:06:37,541 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-02-21 13:06:37,548 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-21 13:06:37,551 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-02-21 13:06:37,551 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-21 13:06:37,551 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-21 13:06:37,570 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 36715
2023-02-21 13:06:37,570 INFO org.mortbay.log: jetty-6.1.26
2023-02-21 13:06:37,828 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:36715
2023-02-21 13:06:38,578 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-02-21 13:06:38,597 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-21 13:06:38,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ganesh
2023-02-21 13:06:38,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-02-21 13:06:38,874 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-21 13:06:38,917 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-02-21 13:06:39,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-02-21 13:06:39,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-02-21 13:06:39,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-02-21 13:06:39,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2023-02-21 13:06:39,239 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-21 13:06:39,243 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-02-21 13:06:40,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2023-02-21 13:06:40,058 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2023-02-21 13:06:40,100 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on home/ganesh/Desktop/HADOOP_F2/in_use.lock acquired by nodename 3811@ganesh-virtual-machine
2023-02-21 13:06:40,332 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-133797978-127.0.1.1-1675826040519
2023-02-21 13:06:40,333 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519
2023-02-21 13:06:40,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=648504085;bpid=BP-133797978-127.0.1.1-1675826040519;lv=-57;nsInfo=lv=-63;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519;bpid=BP-133797978-127.0.1.1-1675826040519;dnuuid=4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-21 13:06:40,556 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-3162c58e-bc52-4f4c-9217-6d1817d697b3
2023-02-21 13:06:40,556 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - home/ganesh/Desktop/HADOOP_F2/current, StorageType: DISK
2023-02-21 13:06:40,582 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-02-21 13:06:40,592 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2023-02-21 13:06:40,592 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-133797978-127.0.1.1-1675826040519
2023-02-21 13:06:40,611 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-21 13:06:40,733 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-133797978-127.0.1.1-1675826040519 on /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 114ms
2023-02-21 13:06:40,733 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-133797978-127.0.1.1-1675826040519: 141ms
2023-02-21 13:06:40,744 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-21 13:06:40,744 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/replicas doesn't exist 
2023-02-21 13:06:40,767 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 23ms
2023-02-21 13:06:40,768 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 31ms
2023-02-21 13:06:40,920 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(home/ganesh/Desktop/HADOOP_F2, DS-3162c58e-bc52-4f4c-9217-6d1817d697b3): no suitable block pools found to scan.  Waiting 634793849 ms.
2023-02-21 13:06:40,945 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/21/23 4:41 PM with interval of 21600000ms
2023-02-21 13:06:40,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2023-02-21 13:06:41,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 successfully registered with NN
2023-02-21 13:06:41,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-02-21 13:06:41,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xcdcdb6e2a21396f0,  containing 1 storage report(s), of which we sent 1. The reports had 14 total blocks and used 1 RPC(s). This took 6 msec to generate and 118 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-21 13:06:41,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-21 13:17:26,756 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-21 13:17:26,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-21 13:21:21,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-21 13:21:21,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-21 13:21:22,875 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-21 13:21:23,016 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-21 13:21:23,016 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-02-21 13:21:23,026 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-02-21 13:21:23,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ganesh-virtual-machine
2023-02-21 13:21:23,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-02-21 13:21:23,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-02-21 13:21:23,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2023-02-21 13:21:23,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2023-02-21 13:21:23,294 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-21 13:21:23,304 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-21 13:21:23,312 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-02-21 13:21:23,320 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-21 13:21:23,322 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-02-21 13:21:23,322 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-21 13:21:23,323 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-21 13:21:23,343 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45135
2023-02-21 13:21:23,343 INFO org.mortbay.log: jetty-6.1.26
2023-02-21 13:21:23,560 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45135
2023-02-21 13:21:24,126 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-02-21 13:21:24,139 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-21 13:21:24,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ganesh
2023-02-21 13:21:24,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-02-21 13:21:24,279 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-21 13:21:24,320 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-02-21 13:21:24,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-02-21 13:21:24,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-02-21 13:21:24,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-02-21 13:21:24,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2023-02-21 13:21:24,533 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-21 13:21:24,538 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-02-21 13:21:25,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2023-02-21 13:21:25,661 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2023-02-21 13:21:25,690 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on home/ganesh/Desktop/HADOOP_F2/in_use.lock acquired by nodename 2826@ganesh-virtual-machine
2023-02-21 13:21:26,001 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-133797978-127.0.1.1-1675826040519
2023-02-21 13:21:26,002 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519
2023-02-21 13:21:26,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=648504085;bpid=BP-133797978-127.0.1.1-1675826040519;lv=-57;nsInfo=lv=-63;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519;bpid=BP-133797978-127.0.1.1-1675826040519;dnuuid=4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-21 13:21:26,201 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-3162c58e-bc52-4f4c-9217-6d1817d697b3
2023-02-21 13:21:26,201 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - home/ganesh/Desktop/HADOOP_F2/current, StorageType: DISK
2023-02-21 13:21:26,222 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-02-21 13:21:26,252 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2023-02-21 13:21:26,253 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-133797978-127.0.1.1-1675826040519
2023-02-21 13:21:26,260 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-21 13:21:26,311 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current: 155648
2023-02-21 13:21:26,317 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-133797978-127.0.1.1-1675826040519 on /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 55ms
2023-02-21 13:21:26,329 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-133797978-127.0.1.1-1675826040519: 77ms
2023-02-21 13:21:26,338 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-21 13:21:26,338 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/replicas doesn't exist 
2023-02-21 13:21:26,363 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 25ms
2023-02-21 13:21:26,371 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 40ms
2023-02-21 13:21:26,669 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(home/ganesh/Desktop/HADOOP_F2, DS-3162c58e-bc52-4f4c-9217-6d1817d697b3): no suitable block pools found to scan.  Waiting 633908100 ms.
2023-02-21 13:21:26,694 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/21/23 1:48 PM with interval of 21600000ms
2023-02-21 13:21:26,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2023-02-21 13:21:26,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 successfully registered with NN
2023-02-21 13:21:26,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-02-21 13:21:27,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x734fb30e4af8b5c6,  containing 1 storage report(s), of which we sent 1. The reports had 14 total blocks and used 1 RPC(s). This took 13 msec to generate and 165 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-21 13:21:27,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-21 13:26:09,427 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1042ms
No GCs detected
2023-02-21 13:48:50,709 ERROR org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Error compiling report
java.util.concurrent.ExecutionException: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.getDiskReport(DirectoryScanner.java:735)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.scan(DirectoryScanner.java:586)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.reconcile(DirectoryScanner.java:567)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.run(DirectoryScanner.java:512)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfo.getSuffix(DirectoryScanner.java:290)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfo.<init>(DirectoryScanner.java:306)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:899)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:872)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:872)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:820)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:782)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	... 3 more
2023-02-21 13:48:50,715 ERROR org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Exception during DirectoryScanner execution - will continue next cycle
java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.getDiskReport(DirectoryScanner.java:745)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.scan(DirectoryScanner.java:586)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.reconcile(DirectoryScanner.java:567)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.run(DirectoryScanner.java:512)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.getDiskReport(DirectoryScanner.java:735)
	... 10 more
Caused by: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfo.getSuffix(DirectoryScanner.java:290)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfo.<init>(DirectoryScanner.java:306)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:899)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:872)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:872)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:820)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:782)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	... 3 more
2023-02-21 15:40:36,117 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1028ms
No GCs detected
2023-02-21 15:42:06,470 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-21 15:42:06,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-23 12:30:41,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-23 12:30:41,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-23 12:30:43,069 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-23 12:30:43,348 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-23 12:30:43,348 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-02-23 12:30:43,367 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-02-23 12:30:43,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ganesh-virtual-machine
2023-02-23 12:30:43,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-02-23 12:30:43,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-02-23 12:30:43,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2023-02-23 12:30:43,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2023-02-23 12:30:43,778 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-23 12:30:43,793 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-23 12:30:43,809 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-02-23 12:30:43,819 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-23 12:30:43,822 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-02-23 12:30:43,822 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-23 12:30:43,822 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-23 12:30:43,848 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45393
2023-02-23 12:30:43,848 INFO org.mortbay.log: jetty-6.1.26
2023-02-23 12:30:44,114 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45393
2023-02-23 12:30:45,093 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-02-23 12:30:45,099 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-23 12:30:45,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ganesh
2023-02-23 12:30:45,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-02-23 12:30:45,326 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-23 12:30:45,370 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-02-23 12:30:45,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-02-23 12:30:45,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-02-23 12:30:45,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-02-23 12:30:45,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2023-02-23 12:30:45,680 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-23 12:30:45,689 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-02-23 12:30:46,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2023-02-23 12:30:46,663 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2023-02-23 12:30:46,676 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on home/ganesh/Desktop/HADOOP_F2/in_use.lock acquired by nodename 7311@ganesh-virtual-machine
2023-02-23 12:30:46,855 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-133797978-127.0.1.1-1675826040519
2023-02-23 12:30:46,855 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519
2023-02-23 12:30:46,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=648504085;bpid=BP-133797978-127.0.1.1-1675826040519;lv=-57;nsInfo=lv=-63;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519;bpid=BP-133797978-127.0.1.1-1675826040519;dnuuid=4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-23 12:30:47,012 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-3162c58e-bc52-4f4c-9217-6d1817d697b3
2023-02-23 12:30:47,012 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - home/ganesh/Desktop/HADOOP_F2/current, StorageType: DISK
2023-02-23 12:30:47,032 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-02-23 12:30:47,052 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2023-02-23 12:30:47,052 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-133797978-127.0.1.1-1675826040519
2023-02-23 12:30:47,054 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-23 12:30:47,146 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-133797978-127.0.1.1-1675826040519 on /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 91ms
2023-02-23 12:30:47,147 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-133797978-127.0.1.1-1675826040519: 95ms
2023-02-23 12:30:47,155 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-23 12:30:47,155 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/replicas doesn't exist 
2023-02-23 12:30:47,169 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 14ms
2023-02-23 12:30:47,169 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 20ms
2023-02-23 12:30:47,359 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(home/ganesh/Desktop/HADOOP_F2, DS-3162c58e-bc52-4f4c-9217-6d1817d697b3): no suitable block pools found to scan.  Waiting 464147411 ms.
2023-02-23 12:30:47,374 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/23/23 5:08 PM with interval of 21600000ms
2023-02-23 12:30:47,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2023-02-23 12:30:47,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 successfully registered with NN
2023-02-23 12:30:47,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-02-23 12:30:48,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xec9f56963191d3de,  containing 1 storage report(s), of which we sent 1. The reports had 14 total blocks and used 1 RPC(s). This took 6 msec to generate and 181 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-23 12:30:48,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-23 12:42:14,950 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-23 12:42:15,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-23 22:21:29,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-23 22:21:29,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-23 22:21:30,958 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-23 22:21:31,126 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-23 22:21:31,126 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-02-23 22:21:31,149 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-02-23 22:21:31,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ganesh-virtual-machine
2023-02-23 22:21:31,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-02-23 22:21:31,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-02-23 22:21:31,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2023-02-23 22:21:31,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2023-02-23 22:21:31,521 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-23 22:21:31,532 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-23 22:21:31,542 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-02-23 22:21:31,553 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-23 22:21:31,557 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-02-23 22:21:31,557 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-23 22:21:31,557 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-23 22:21:31,584 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 36005
2023-02-23 22:21:31,584 INFO org.mortbay.log: jetty-6.1.26
2023-02-23 22:21:31,843 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:36005
2023-02-23 22:21:32,278 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-02-23 22:21:32,283 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-23 22:21:32,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ganesh
2023-02-23 22:21:32,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-02-23 22:21:32,387 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-23 22:21:32,427 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-02-23 22:21:32,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-02-23 22:21:32,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-02-23 22:21:32,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-02-23 22:21:32,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2023-02-23 22:21:32,579 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-23 22:21:32,584 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-02-23 22:21:33,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2023-02-23 22:21:33,648 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2023-02-23 22:21:33,674 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on home/ganesh/Desktop/HADOOP_F2/in_use.lock acquired by nodename 4837@ganesh-virtual-machine
2023-02-23 22:21:34,142 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-133797978-127.0.1.1-1675826040519
2023-02-23 22:21:34,142 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519
2023-02-23 22:21:34,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=648504085;bpid=BP-133797978-127.0.1.1-1675826040519;lv=-57;nsInfo=lv=-63;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519;bpid=BP-133797978-127.0.1.1-1675826040519;dnuuid=4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-23 22:21:34,391 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-3162c58e-bc52-4f4c-9217-6d1817d697b3
2023-02-23 22:21:34,391 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - home/ganesh/Desktop/HADOOP_F2/current, StorageType: DISK
2023-02-23 22:21:34,422 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-02-23 22:21:34,449 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2023-02-23 22:21:34,449 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-133797978-127.0.1.1-1675826040519
2023-02-23 22:21:34,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-23 22:21:34,561 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-133797978-127.0.1.1-1675826040519 on /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 103ms
2023-02-23 22:21:34,567 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-133797978-127.0.1.1-1675826040519: 118ms
2023-02-23 22:21:34,578 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-23 22:21:34,578 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/replicas doesn't exist 
2023-02-23 22:21:34,619 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 41ms
2023-02-23 22:21:34,619 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 46ms
2023-02-23 22:21:34,816 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(home/ganesh/Desktop/HADOOP_F2, DS-3162c58e-bc52-4f4c-9217-6d1817d697b3): no suitable block pools found to scan.  Waiting 428699953 ms.
2023-02-23 22:21:34,841 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/24/23 2:14 AM with interval of 21600000ms
2023-02-23 22:21:34,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2023-02-23 22:21:35,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 successfully registered with NN
2023-02-23 22:21:35,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-02-23 22:21:35,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1fbaa56fa204e33a,  containing 1 storage report(s), of which we sent 1. The reports had 14 total blocks and used 1 RPC(s). This took 6 msec to generate and 164 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-23 22:21:35,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-23 22:26:10,205 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1253ms
No GCs detected
2023-02-23 22:35:54,096 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5037ms
No GCs detected
2023-02-23 22:36:06,015 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5387ms
No GCs detected
2023-02-23 22:36:20,534 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5403ms
No GCs detected
2023-02-23 22:36:47,330 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12947ms
No GCs detected
2023-02-23 22:49:26,200 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5065ms
No GCs detected
2023-02-23 22:49:32,276 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5064ms
No GCs detected
2023-02-23 22:49:41,375 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4993ms
No GCs detected
2023-02-23 22:49:45,027 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5231ms
No GCs detected
2023-02-23 22:50:01,015 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5400ms
No GCs detected
2023-02-23 22:50:10,978 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4962ms
No GCs detected
2023-02-23 22:50:18,230 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5251ms
No GCs detected
2023-02-23 22:50:24,135 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5404ms
No GCs detected
2023-02-23 22:50:29,074 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5093ms
No GCs detected
2023-02-23 22:50:36,428 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5333ms
No GCs detected
2023-02-23 22:50:42,219 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5318ms
No GCs detected
2023-02-23 22:50:51,258 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5373ms
No GCs detected
2023-02-23 22:50:57,061 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5303ms
No GCs detected
2023-02-23 22:51:11,467 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5403ms
No GCs detected
2023-02-23 22:51:21,706 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5299ms
No GCs detected
2023-02-23 22:52:47,535 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9300ms
No GCs detected
2023-02-23 22:54:22,328 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7769ms
No GCs detected
2023-02-23 22:54:54,800 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4979ms
No GCs detected
2023-02-23 23:13:08,703 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2903ms
No GCs detected
2023-02-24 00:24:21,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741840_1016 src: /127.0.0.1:57810 dest: /127.0.0.1:50010
2023-02-24 00:24:23,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741841_1017 src: /127.0.0.1:59240 dest: /127.0.0.1:50010
2023-02-24 00:24:25,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741842_1018 src: /127.0.0.1:59242 dest: /127.0.0.1:50010
2023-02-24 00:24:25,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741843_1019 src: /127.0.0.1:59266 dest: /127.0.0.1:50010
2023-02-24 00:24:25,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59266, dest: /127.0.0.1:50010, bytes: 312, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1075336992_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741843_1019, duration: 17527163
2023-02-24 00:24:25,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2023-02-24 00:24:25,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741844_1020 src: /127.0.0.1:59272 dest: /127.0.0.1:50010
2023-02-24 00:24:25,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59272, dest: /127.0.0.1:50010, bytes: 42, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1075336992_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741844_1020, duration: 5046149
2023-02-24 00:24:25,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2023-02-24 00:24:28,133 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741839_1015 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741839 for deletion
2023-02-24 00:24:28,137 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-133797978-127.0.1.1-1675826040519 blk_1073741839_1015 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741839
2023-02-24 00:24:31,051 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2023-02-24 00:24:31,052 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741834_1010 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741834 for deletion
2023-02-24 00:24:31,053 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-133797978-127.0.1.1-1675826040519 blk_1073741833_1009 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741833
2023-02-24 00:24:31,053 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-133797978-127.0.1.1-1675826040519 blk_1073741834_1010 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741834
2023-02-24 00:24:48,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59242, dest: /127.0.0.1:50010, bytes: 4294, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1075336992_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741842_1018, duration: 23396202613
2023-02-24 00:24:48,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2023-02-24 00:24:52,056 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741842_1018 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2023-02-24 00:24:52,060 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-133797978-127.0.1.1-1675826040519 blk_1073741842_1018 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741842
2023-02-24 00:25:22,060 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
2023-02-24 00:25:22,061 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-133797978-127.0.1.1-1675826040519 blk_1073741829_1005 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741829
2023-02-24 00:25:22,061 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2023-02-24 00:25:22,061 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-133797978-127.0.1.1-1675826040519 blk_1073741830_1006 file /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741830
2023-02-24 00:25:22,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741845_1021 src: /127.0.0.1:38910 dest: /127.0.0.1:50010
2023-02-24 00:25:22,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741846_1022 src: /127.0.0.1:38926 dest: /127.0.0.1:50010
2023-02-24 00:25:22,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38926, dest: /127.0.0.1:50010, bytes: 536, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1075336992_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741846_1022, duration: 6853050
2023-02-24 00:25:22,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2023-02-24 00:25:23,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741847_1023 src: /127.0.0.1:38938 dest: /127.0.0.1:50010
2023-02-24 00:25:23,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38938, dest: /127.0.0.1:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1075336992_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741847_1023, duration: 5632792
2023-02-24 00:25:23,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2023-02-24 00:27:14,546 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-24 00:27:14,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-24 01:57:30,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-24 01:57:30,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-24 01:57:31,412 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-24 01:57:31,526 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-24 01:57:31,526 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-02-24 01:57:31,538 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-02-24 01:57:31,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ganesh-virtual-machine
2023-02-24 01:57:31,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-02-24 01:57:31,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-02-24 01:57:31,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2023-02-24 01:57:31,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2023-02-24 01:57:31,849 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-24 01:57:31,858 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-24 01:57:31,872 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-02-24 01:57:31,881 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-24 01:57:31,884 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-02-24 01:57:31,884 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-24 01:57:31,884 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-24 01:57:31,904 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 33845
2023-02-24 01:57:31,905 INFO org.mortbay.log: jetty-6.1.26
2023-02-24 01:57:32,180 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:33845
2023-02-24 01:57:32,828 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-02-24 01:57:32,835 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-24 01:57:32,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ganesh
2023-02-24 01:57:32,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-02-24 01:57:32,953 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-24 01:57:32,992 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-02-24 01:57:33,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-02-24 01:57:33,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-02-24 01:57:33,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-02-24 01:57:33,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2023-02-24 01:57:33,176 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-24 01:57:33,181 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-02-24 01:57:34,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2023-02-24 01:57:34,352 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2023-02-24 01:57:34,362 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on home/ganesh/Desktop/HADOOP_F2/in_use.lock acquired by nodename 3136@ganesh-virtual-machine
2023-02-24 01:57:34,504 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-133797978-127.0.1.1-1675826040519
2023-02-24 01:57:34,504 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519
2023-02-24 01:57:34,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=648504085;bpid=BP-133797978-127.0.1.1-1675826040519;lv=-57;nsInfo=lv=-63;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519;bpid=BP-133797978-127.0.1.1-1675826040519;dnuuid=4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-24 01:57:34,670 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-3162c58e-bc52-4f4c-9217-6d1817d697b3
2023-02-24 01:57:34,671 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - home/ganesh/Desktop/HADOOP_F2/current, StorageType: DISK
2023-02-24 01:57:34,686 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-02-24 01:57:34,707 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2023-02-24 01:57:34,707 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-133797978-127.0.1.1-1675826040519
2023-02-24 01:57:34,709 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-24 01:57:34,770 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-133797978-127.0.1.1-1675826040519 on /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 61ms
2023-02-24 01:57:34,770 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-133797978-127.0.1.1-1675826040519: 63ms
2023-02-24 01:57:34,779 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-24 01:57:34,780 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/replicas doesn't exist 
2023-02-24 01:57:34,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 46ms
2023-02-24 01:57:34,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 54ms
2023-02-24 01:57:34,981 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(home/ganesh/Desktop/HADOOP_F2, DS-3162c58e-bc52-4f4c-9217-6d1817d697b3): no suitable block pools found to scan.  Waiting 415739788 ms.
2023-02-24 01:57:35,003 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/24/23 6:13 AM with interval of 21600000ms
2023-02-24 01:57:35,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2023-02-24 01:57:35,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 successfully registered with NN
2023-02-24 01:57:35,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-02-24 01:57:36,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x758fabd28bfa4d79,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 11 msec to generate and 284 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-24 01:57:36,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-24 02:03:11,499 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "ganesh-virtual-machine/127.0.1.1"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:154)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:456)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:577)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:771)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1786)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1155)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1052)
2023-02-24 02:03:15,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 02:03:16,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 02:03:16,867 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-24 02:03:16,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-24 02:04:57,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-24 02:04:57,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-24 02:04:58,376 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-24 02:04:58,472 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-24 02:04:58,472 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-02-24 02:04:58,481 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-02-24 02:04:58,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ganesh-virtual-machine
2023-02-24 02:04:58,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-02-24 02:04:58,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-02-24 02:04:58,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2023-02-24 02:04:58,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2023-02-24 02:04:58,697 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-24 02:04:58,706 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-24 02:04:58,714 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-02-24 02:04:58,721 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-24 02:04:58,724 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-02-24 02:04:58,724 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-24 02:04:58,724 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-24 02:04:58,742 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35539
2023-02-24 02:04:58,742 INFO org.mortbay.log: jetty-6.1.26
2023-02-24 02:04:58,902 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:35539
2023-02-24 02:04:59,309 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-02-24 02:04:59,324 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-24 02:04:59,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ganesh
2023-02-24 02:04:59,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-02-24 02:04:59,400 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-24 02:04:59,437 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-02-24 02:04:59,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-02-24 02:04:59,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-02-24 02:04:59,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-02-24 02:04:59,593 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-24 02:04:59,594 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-02-24 02:04:59,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2023-02-24 02:04:59,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2023-02-24 02:04:59,972 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2023-02-24 02:04:59,979 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on home/ganesh/Desktop/HADOOP_F2/in_use.lock acquired by nodename 5288@ganesh-virtual-machine
2023-02-24 02:05:00,079 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-133797978-127.0.1.1-1675826040519
2023-02-24 02:05:00,079 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519
2023-02-24 02:05:00,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=648504085;bpid=BP-133797978-127.0.1.1-1675826040519;lv=-57;nsInfo=lv=-63;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519;bpid=BP-133797978-127.0.1.1-1675826040519;dnuuid=4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-24 02:05:00,175 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-3162c58e-bc52-4f4c-9217-6d1817d697b3
2023-02-24 02:05:00,175 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - home/ganesh/Desktop/HADOOP_F2/current, StorageType: DISK
2023-02-24 02:05:00,184 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-02-24 02:05:00,199 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2023-02-24 02:05:00,199 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-133797978-127.0.1.1-1675826040519
2023-02-24 02:05:00,201 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-24 02:05:00,220 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current: 176128
2023-02-24 02:05:00,239 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-133797978-127.0.1.1-1675826040519 on /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 38ms
2023-02-24 02:05:00,240 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-133797978-127.0.1.1-1675826040519: 40ms
2023-02-24 02:05:00,247 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-24 02:05:00,247 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/replicas doesn't exist 
2023-02-24 02:05:00,267 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 20ms
2023-02-24 02:05:00,267 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 25ms
2023-02-24 02:05:00,383 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(home/ganesh/Desktop/HADOOP_F2, DS-3162c58e-bc52-4f4c-9217-6d1817d697b3): no suitable block pools found to scan.  Waiting 415294386 ms.
2023-02-24 02:05:00,393 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/24/23 5:18 AM with interval of 21600000ms
2023-02-24 02:05:00,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2023-02-24 02:05:00,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 successfully registered with NN
2023-02-24 02:05:00,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-02-24 02:05:00,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xd22fb77fd75b203,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 14 msec to generate and 199 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-24 02:05:00,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-24 02:06:44,346 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1099ms
No GCs detected
2023-02-24 02:27:58,279 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-24 02:27:58,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-24 13:20:22,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-24 13:20:22,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-24 13:20:24,056 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-24 13:20:24,434 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-24 13:20:24,434 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-02-24 13:20:24,451 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-02-24 13:20:24,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ganesh-virtual-machine
2023-02-24 13:20:24,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-02-24 13:20:24,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-02-24 13:20:24,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2023-02-24 13:20:24,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2023-02-24 13:20:24,875 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-24 13:20:24,887 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-24 13:20:24,902 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-02-24 13:20:24,911 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-24 13:20:24,914 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-02-24 13:20:24,915 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-24 13:20:24,915 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-24 13:20:24,950 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40099
2023-02-24 13:20:24,950 INFO org.mortbay.log: jetty-6.1.26
2023-02-24 13:20:25,193 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40099
2023-02-24 13:20:26,480 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-02-24 13:20:26,510 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-24 13:20:26,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ganesh
2023-02-24 13:20:26,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-02-24 13:20:26,796 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-24 13:20:26,839 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-02-24 13:20:26,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-02-24 13:20:27,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-02-24 13:20:27,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-02-24 13:20:27,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2023-02-24 13:20:27,180 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-24 13:20:27,194 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-02-24 13:20:28,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:29,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:30,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:31,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:32,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:33,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:34,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:35,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:36,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:37,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:37,566 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:20:37,600 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:20:43,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:44,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:45,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:46,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:47,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:48,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:49,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:50,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:51,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:52,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:52,617 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:20:52,618 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:20:58,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:20:59,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:00,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:01,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:02,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:03,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:04,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:05,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:06,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:07,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:07,637 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:21:07,638 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:21:13,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:14,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:15,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:16,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:17,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:18,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:19,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:20,653 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:21,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:22,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:22,658 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:21:22,659 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:21:28,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:29,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:30,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:31,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:32,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:33,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:34,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:35,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:36,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:37,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:37,678 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:21:37,680 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:21:43,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:44,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:45,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:46,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:47,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:48,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:49,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:50,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:51,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:52,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:52,703 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:21:52,704 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:21:58,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:21:59,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:00,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:02,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:03,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:04,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:05,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:06,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:07,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:08,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:08,262 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:22:08,270 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:22:14,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:15,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:16,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:17,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:18,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:19,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:20,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:21,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:22,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:23,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:23,284 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:22:23,285 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:22:29,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:30,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:31,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:32,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:33,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:34,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:35,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:36,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:37,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:38,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:38,802 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:22:38,804 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:22:44,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:45,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:46,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:47,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:48,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:49,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:50,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:51,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:52,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:53,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:22:53,844 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:22:53,845 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:22:59,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:00,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:01,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:02,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:03,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:04,856 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:05,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:06,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:07,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:08,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:08,863 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:23:08,864 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:23:14,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:15,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:16,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:17,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:18,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:19,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:20,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:21,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:22,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:23,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:23,881 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:23:23,882 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:23:29,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:30,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:31,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:32,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:33,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:34,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:35,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:36,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:37,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:38,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:38,906 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:23:38,907 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:23:44,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:45,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:46,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:47,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:48,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:49,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:50,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:51,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:52,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:53,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:23:53,921 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:23:53,923 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:23:59,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:00,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:01,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:02,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:03,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:04,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:05,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:06,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:07,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:08,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:08,941 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:24:08,942 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:24:14,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:15,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:16,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:17,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:18,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:19,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:20,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:21,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:22,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:23,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:23,957 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:24:23,959 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:24:29,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:30,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:31,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:32,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:33,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:34,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:35,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:36,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:37,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:38,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:38,977 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:24:38,978 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:24:44,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:45,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:46,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:47,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:48,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:49,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:50,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:51,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:52,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:53,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:24:53,995 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:24:53,996 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:24:59,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:01,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:02,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:03,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:04,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:05,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:06,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:07,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:08,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:09,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:09,058 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:25:09,059 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:25:15,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:16,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:17,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:18,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:19,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:20,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:21,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:22,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:23,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:24,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:24,074 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:25:24,082 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:25:30,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:31,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:32,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:33,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:34,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:35,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:36,092 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:37,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:38,094 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:39,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:39,097 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:25:39,099 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:25:45,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:46,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:47,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:48,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:49,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:50,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:51,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:52,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:53,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:54,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:25:54,112 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:25:54,113 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:26:00,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:01,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:02,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:03,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:04,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:05,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:06,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:07,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:08,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:09,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:09,133 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:26:09,134 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:26:15,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:16,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:17,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:18,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:19,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:20,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:21,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:22,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:23,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:24,148 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:24,149 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:26:24,150 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:26:30,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:31,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:32,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:33,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:34,159 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:35,160 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:36,161 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:37,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:38,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:39,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:39,165 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:26:39,171 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:26:45,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:46,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:47,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:48,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:49,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:50,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:51,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:52,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:53,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:54,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:26:54,206 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:26:54,208 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:27:00,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:01,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:02,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:03,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:04,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:05,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:06,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:07,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:08,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:09,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:09,234 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:27:09,235 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:27:15,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:16,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:17,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:18,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:19,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:20,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:21,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:22,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:23,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:24,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:24,251 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:27:24,253 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:27:30,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:31,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:32,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:33,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:34,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:35,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:36,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:37,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:38,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:39,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:39,292 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:27:39,293 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:27:45,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:46,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:47,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:48,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:49,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:50,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:51,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:52,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:53,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:54,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:27:54,324 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:27:54,325 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:28:00,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:01,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:02,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:03,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:04,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:05,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:06,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:07,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:08,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:09,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:09,342 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:28:09,344 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:28:15,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:16,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:17,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:18,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:19,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:20,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:21,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:22,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:23,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:24,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:24,366 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:28:24,367 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:28:30,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:31,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:32,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:33,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:34,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:35,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:36,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:37,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:38,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:39,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:39,383 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:28:39,384 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:28:45,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:46,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:47,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:48,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:49,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:50,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:51,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:52,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:53,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:54,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:28:54,407 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:28:54,408 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:29:00,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:01,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:02,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:03,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:04,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:05,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:06,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:07,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:08,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:09,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:09,424 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:29:09,425 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:29:15,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:16,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:17,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:18,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:19,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:20,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:21,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:22,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:23,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:24,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:24,438 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:29:24,439 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:29:30,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:31,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:32,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:33,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:34,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:35,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:36,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:37,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:38,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:39,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:39,458 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:29:39,459 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:29:45,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:46,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:47,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:48,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:49,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:50,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:51,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:52,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:53,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:54,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:29:54,473 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:29:54,475 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:30:00,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:01,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:02,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:03,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:04,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:05,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:06,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:07,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:08,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:09,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:09,490 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:30:09,491 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:30:15,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:16,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:17,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:18,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:19,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:20,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:21,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:22,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:23,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:24,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:24,506 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:30:24,507 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:30:27,228 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:163)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:2942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:72)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:276)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:30:27,236 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:2922)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:72)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:276)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:30:30,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:31,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:32,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:33,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:34,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:35,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:36,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:37,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:38,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:39,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:39,529 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:30:39,533 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:30:45,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:46,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:47,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:48,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:49,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:50,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:51,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:52,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:53,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:54,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:30:54,563 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:30:54,566 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:31:00,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:01,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:02,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:03,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:04,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:05,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:06,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:07,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:08,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:09,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:09,584 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:31:09,585 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:31:15,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:16,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:17,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:18,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:19,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:20,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:21,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:22,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:23,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:24,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:24,607 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:31:24,608 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:31:30,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:31,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:32,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:33,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:34,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:35,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:36,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:37,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:38,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:39,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:39,620 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:31:39,621 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:31:45,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:46,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:48,721 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1109ms
No GCs detected
2023-02-24 13:31:48,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:49,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:50,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:51,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:52,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:53,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:54,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:55,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:31:55,748 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:31:55,749 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:32:01,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:02,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:03,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:04,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:05,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:06,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:07,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:08,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:09,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:10,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:10,777 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:32:10,778 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:32:16,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:17,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:18,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:20,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:21,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:22,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:23,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:24,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:25,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:26,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:26,706 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:32:26,707 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:32:32,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:33,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:34,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:35,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:36,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:37,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:38,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:39,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:40,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:41,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:41,719 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:32:41,720 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:32:47,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:48,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:49,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:50,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:51,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:52,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:53,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:54,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:55,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:56,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:32:56,735 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:32:56,736 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:33:02,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:03,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:04,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:05,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:06,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:07,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:08,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:09,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:10,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:12,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:12,675 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:33:12,676 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:33:18,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:19,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:20,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:21,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:22,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:23,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:24,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:25,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:26,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:27,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:27,690 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:33:27,692 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:33:33,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:34,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:35,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:36,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:37,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:38,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:39,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:40,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:41,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:42,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:42,704 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:33:42,706 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:33:48,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:49,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:50,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:51,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:52,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:53,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:54,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:55,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:56,720 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:57,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:33:57,722 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:33:57,723 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:34:03,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:04,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:05,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:06,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:07,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:08,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:09,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:10,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:11,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:12,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:12,738 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:34:12,739 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:34:18,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:19,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:20,752 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:21,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:22,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:23,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:24,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:25,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:26,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:27,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:27,774 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:34:27,776 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:34:33,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:34,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:35,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:36,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:37,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:38,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:39,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:40,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:41,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:42,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:42,790 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:34:42,792 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:34:48,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:49,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:50,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:51,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:52,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:53,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:54,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:55,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:56,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:57,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:34:57,808 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:34:57,809 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:35:03,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:04,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:05,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:06,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:07,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:08,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:09,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:10,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:11,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:12,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:12,825 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:35:12,827 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:35:18,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:19,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:20,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:21,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:22,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:23,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:24,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:25,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:26,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:27,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:27,842 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:35:27,843 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:35:33,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:34,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:35,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:36,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:37,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:38,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:39,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:40,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:41,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:42,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:42,866 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:35:42,868 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:35:48,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:49,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:50,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:51,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:52,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:53,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:54,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:55,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:56,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:57,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:35:57,893 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:35:57,896 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:36:03,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:04,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:05,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:06,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:07,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:08,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:09,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:10,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:11,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:12,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:12,910 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:36:12,911 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:36:18,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:19,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:20,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:21,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:22,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:23,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:24,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:25,921 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:26,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:27,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:27,924 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:36:27,925 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:36:33,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:34,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:35,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:36,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:37,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:38,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:39,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:40,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:41,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:42,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:42,941 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:36:42,942 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:36:48,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:49,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:50,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:51,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:52,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:53,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:54,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:55,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:56,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:57,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:36:57,957 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:36:57,958 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:37:04,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:05,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:06,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:07,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:08,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:09,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:10,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:11,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:12,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:13,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:13,307 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:37:13,308 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:37:19,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:20,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:21,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:22,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:23,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:24,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:25,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:26,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:27,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:28,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:28,323 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:37:28,324 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:37:34,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:35,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:36,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:37,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:38,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:39,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:40,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:41,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:42,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:43,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:43,335 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:37:43,336 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:37:49,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:50,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:51,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:52,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:53,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:54,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:55,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:56,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:57,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:58,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:37:58,356 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:37:58,357 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:38:04,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:05,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:06,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:07,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:08,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:09,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:10,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:11,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:12,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:13,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:13,835 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:38:13,836 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:38:19,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:20,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:21,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:22,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:23,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:24,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:25,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:26,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:27,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:28,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:28,850 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:38:28,851 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:38:34,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:35,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:36,856 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:37,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:38,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:39,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:40,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:41,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:42,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:43,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:43,866 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:38:43,867 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:38:49,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:50,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:51,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:52,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:53,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:54,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:55,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:56,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:57,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:58,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:38:58,881 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:38:58,882 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:39:04,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:05,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:06,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:07,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:08,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:09,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:10,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:11,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:12,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:13,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:13,897 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:39:13,898 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:39:19,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:20,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:21,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:22,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:23,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:24,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:25,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:26,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:27,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:28,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:28,936 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:39:28,938 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:39:34,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:35,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:36,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:37,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:38,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:39,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:40,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:41,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:42,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:43,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:43,951 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:39:43,954 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:39:49,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:50,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:51,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:52,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:53,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:54,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:55,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:56,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:57,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:58,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:39:58,970 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:39:58,971 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:40:04,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:05,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:06,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:07,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:08,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:09,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:10,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:11,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:12,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:13,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:13,995 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:40:13,997 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:40:19,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:21,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:22,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:23,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:24,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:25,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:26,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:27,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:27,261 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:163)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:2942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:72)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:276)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:40:27,264 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:2922)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:72)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:276)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:40:28,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:29,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:29,011 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:40:29,012 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:40:35,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:36,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:37,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:38,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:39,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:40,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:41,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:42,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:43,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:44,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:44,030 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:40:44,031 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:40:50,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:51,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:52,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:53,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:54,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:55,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:56,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:57,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:58,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:59,061 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:40:59,062 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:40:59,063 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:41:05,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:06,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:07,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:08,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:09,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:10,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:11,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:12,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:13,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:14,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:14,090 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:41:14,092 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:41:20,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:21,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:22,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:23,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:24,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:25,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:26,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:27,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:28,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:29,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:29,117 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:41:29,121 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:41:36,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:37,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:38,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:39,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:40,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:41,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:42,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:43,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:44,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:45,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:45,049 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:41:45,051 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:41:51,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:52,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:53,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:54,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:55,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:56,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:57,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:58,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:41:59,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:00,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:00,433 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:42:00,434 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:42:06,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:07,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:08,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:09,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:10,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:11,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:12,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:13,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:14,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:15,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:15,451 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:42:15,453 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:42:21,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:22,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:23,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:24,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:25,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:26,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:27,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:28,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:29,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:30,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:30,928 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:42:30,929 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:42:36,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:37,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:38,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:39,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:40,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:41,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:42,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:43,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:44,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:45,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:45,943 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:42:45,944 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:42:51,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:52,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:53,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:54,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:55,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:56,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:57,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:58,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:42:59,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:00,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:00,968 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:43:00,970 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:43:06,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:07,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:08,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:09,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:10,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:11,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:12,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:13,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:14,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:15,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:15,983 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:43:15,984 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:43:21,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:22,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:23,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:24,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:25,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:26,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:27,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:28,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:29,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:30,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-02-24 13:43:31,000 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.versionRequest(DatanodeProtocolClientSideTranslatorPB.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.retrieveNamespaceInfo(BPServiceActor.java:215)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:261)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
	at java.lang.Thread.run(Thread.java:750)
2023-02-24 13:43:31,001 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2023-02-24 13:43:32,267 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-24 13:43:32,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-24 18:46:09,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-24 18:46:09,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-24 18:46:10,695 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-24 18:46:10,842 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-24 18:46:10,842 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-02-24 18:46:10,853 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-02-24 18:46:10,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ganesh-virtual-machine
2023-02-24 18:46:10,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-02-24 18:46:10,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-02-24 18:46:10,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2023-02-24 18:46:10,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2023-02-24 18:46:11,186 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-24 18:46:11,197 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-24 18:46:11,206 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-02-24 18:46:11,215 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-24 18:46:11,217 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-02-24 18:46:11,218 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-24 18:46:11,218 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-24 18:46:11,240 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45669
2023-02-24 18:46:11,240 INFO org.mortbay.log: jetty-6.1.26
2023-02-24 18:46:11,471 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45669
2023-02-24 18:46:12,140 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-02-24 18:46:12,146 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-24 18:46:12,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ganesh
2023-02-24 18:46:12,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-02-24 18:46:12,295 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-24 18:46:12,331 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-02-24 18:46:12,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-02-24 18:46:12,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-02-24 18:46:12,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-02-24 18:46:12,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2023-02-24 18:46:12,609 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-24 18:46:12,611 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-02-24 18:46:13,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2023-02-24 18:46:13,849 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2023-02-24 18:46:13,858 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on home/ganesh/Desktop/HADOOP_F2/in_use.lock acquired by nodename 3467@ganesh-virtual-machine
2023-02-24 18:46:14,068 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-133797978-127.0.1.1-1675826040519
2023-02-24 18:46:14,068 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519
2023-02-24 18:46:14,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=648504085;bpid=BP-133797978-127.0.1.1-1675826040519;lv=-57;nsInfo=lv=-63;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519;bpid=BP-133797978-127.0.1.1-1675826040519;dnuuid=4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-24 18:46:14,188 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-3162c58e-bc52-4f4c-9217-6d1817d697b3
2023-02-24 18:46:14,188 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - home/ganesh/Desktop/HADOOP_F2/current, StorageType: DISK
2023-02-24 18:46:14,193 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-02-24 18:46:14,206 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2023-02-24 18:46:14,206 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-133797978-127.0.1.1-1675826040519
2023-02-24 18:46:14,212 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-24 18:46:14,287 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-133797978-127.0.1.1-1675826040519 on /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 75ms
2023-02-24 18:46:14,288 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-133797978-127.0.1.1-1675826040519: 82ms
2023-02-24 18:46:14,305 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-24 18:46:14,305 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/replicas doesn't exist 
2023-02-24 18:46:14,381 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 76ms
2023-02-24 18:46:14,381 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 78ms
2023-02-24 18:46:14,611 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(home/ganesh/Desktop/HADOOP_F2, DS-3162c58e-bc52-4f4c-9217-6d1817d697b3): no suitable block pools found to scan.  Waiting 355220158 ms.
2023-02-24 18:46:14,637 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/24/23 10:58 PM with interval of 21600000ms
2023-02-24 18:46:14,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2023-02-24 18:46:14,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 successfully registered with NN
2023-02-24 18:46:14,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-02-24 18:46:15,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xe0aa3c0a99fbec67,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 6 msec to generate and 174 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-24 18:46:15,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-24 18:52:08,986 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1118ms
No GCs detected
2023-02-24 19:14:42,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741848_1024 src: /127.0.0.1:54452 dest: /127.0.0.1:50010
2023-02-24 19:14:42,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:54452, dest: /127.0.0.1:50010, bytes: 99253, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_468881648_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741848_1024, duration: 31664304
2023-02-24 19:14:42,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2023-02-24 19:21:00,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741849_1025 src: /127.0.0.1:43112 dest: /127.0.0.1:50010
2023-02-24 19:21:00,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:43112, dest: /127.0.0.1:50010, bytes: 25627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1200741307_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741849_1025, duration: 43944991
2023-02-24 19:21:00,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2023-02-24 19:46:06,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: NameNode at localhost/127.0.0.1:9000 calls recoverBlock(BP-133797978-127.0.1.1-1675826040519:blk_1073741845_1021, targets=[DatanodeInfoWithStorage[127.0.0.1:50010,null,null]], newGenerationStamp=1026, newBlock=null)
2023-02-24 19:46:06,561 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: initReplicaRecovery: blk_1073741845_1021, recoveryId=1026, replica=ReplicaWaitingToBeRecovered, blk_1073741845_1021, RWR
  getNumBytes()     = 5059
  getBytesOnDisk()  = 5059
  getVisibleLength()= -1
  getVolume()       = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current
  getBlockFile()    = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/rbw/blk_1073741845
2023-02-24 19:46:06,562 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: initReplicaRecovery: changing replica state for blk_1073741845_1021 from RWR to RUR
2023-02-24 19:46:06,564 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: updateReplica: BP-133797978-127.0.1.1-1675826040519:blk_1073741845_1021[numBytes=5059,originalReplicaState=RWR], recoveryId=1026, length=5059, replica=ReplicaUnderRecovery, blk_1073741845_1021, RUR
  getNumBytes()     = 5059
  getBytesOnDisk()  = 5059
  getVisibleLength()= -1
  getVolume()       = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current
  getBlockFile()    = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/rbw/blk_1073741845
  recoveryId=1026
  original=ReplicaWaitingToBeRecovered, blk_1073741845_1021, RWR
  getNumBytes()     = 5059
  getBytesOnDisk()  = 5059
  getVisibleLength()= -1
  getVolume()       = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current
  getBlockFile()    = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/rbw/blk_1073741845
2023-02-24 19:46:06,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: NameNode at localhost/127.0.0.1:9000 calls recoverBlock(BP-133797978-127.0.1.1-1675826040519:blk_1073741840_1016, targets=[DatanodeInfoWithStorage[127.0.0.1:50010,null,null]], newGenerationStamp=1027, newBlock=null)
2023-02-24 19:46:06,595 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: initReplicaRecovery: blk_1073741840_1016, recoveryId=1027, replica=ReplicaWaitingToBeRecovered, blk_1073741840_1016, RWR
  getNumBytes()     = 872
  getBytesOnDisk()  = 872
  getVisibleLength()= -1
  getVolume()       = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current
  getBlockFile()    = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/rbw/blk_1073741840
2023-02-24 19:46:06,595 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: initReplicaRecovery: changing replica state for blk_1073741840_1016 from RWR to RUR
2023-02-24 19:46:06,595 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: updateReplica: BP-133797978-127.0.1.1-1675826040519:blk_1073741840_1016[numBytes=872,originalReplicaState=RWR], recoveryId=1027, length=872, replica=ReplicaUnderRecovery, blk_1073741840_1016, RUR
  getNumBytes()     = 872
  getBytesOnDisk()  = 872
  getVisibleLength()= -1
  getVolume()       = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current
  getBlockFile()    = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/rbw/blk_1073741840
  recoveryId=1027
  original=ReplicaWaitingToBeRecovered, blk_1073741840_1016, RWR
  getNumBytes()     = 872
  getBytesOnDisk()  = 872
  getVisibleLength()= -1
  getVolume()       = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current
  getBlockFile()    = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/rbw/blk_1073741840
2023-02-24 19:46:06,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: NameNode at localhost/127.0.0.1:9000 calls recoverBlock(BP-133797978-127.0.1.1-1675826040519:blk_1073741841_1017, targets=[DatanodeInfoWithStorage[127.0.0.1:50010,null,null]], newGenerationStamp=1028, newBlock=null)
2023-02-24 19:46:06,599 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: initReplicaRecovery: blk_1073741841_1017, recoveryId=1028, replica=ReplicaWaitingToBeRecovered, blk_1073741841_1017, RWR
  getNumBytes()     = 1664
  getBytesOnDisk()  = 1664
  getVisibleLength()= -1
  getVolume()       = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current
  getBlockFile()    = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/rbw/blk_1073741841
2023-02-24 19:46:06,599 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: initReplicaRecovery: changing replica state for blk_1073741841_1017 from RWR to RUR
2023-02-24 19:46:06,599 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: updateReplica: BP-133797978-127.0.1.1-1675826040519:blk_1073741841_1017[numBytes=1664,originalReplicaState=RWR], recoveryId=1028, length=1664, replica=ReplicaUnderRecovery, blk_1073741841_1017, RUR
  getNumBytes()     = 1664
  getBytesOnDisk()  = 1664
  getVisibleLength()= -1
  getVolume()       = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current
  getBlockFile()    = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/rbw/blk_1073741841
  recoveryId=1028
  original=ReplicaWaitingToBeRecovered, blk_1073741841_1017, RWR
  getNumBytes()     = 1664
  getBytesOnDisk()  = 1664
  getVisibleLength()= -1
  getVolume()       = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current
  getBlockFile()    = /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/rbw/blk_1073741841
2023-02-24 20:56:34,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xe0aa3c0a99fbec68,  containing 1 storage report(s), of which we sent 1. The reports had 18 total blocks and used 1 RPC(s). This took 1 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-24 20:56:34,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-24 21:45:02,599 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 50604ms
No GCs detected
2023-02-24 23:33:05,565 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1092ms
No GCs detected
2023-02-25 00:54:50,448 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 14495ms
No GCs detected
2023-02-25 01:37:12,466 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-02-25 01:37:12,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ganesh-virtual-machine/127.0.1.1
************************************************************/
2023-02-25 15:11:22,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = ganesh
STARTUP_MSG:   host = ganesh-virtual-machine/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/ganesh/hadoop-2.8.1/etc/hadoop:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/ganesh/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_352
************************************************************/
2023-02-25 15:11:22,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-02-25 15:11:24,143 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-02-25 15:11:24,325 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-25 15:11:24,325 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-02-25 15:11:24,344 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-02-25 15:11:24,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ganesh-virtual-machine
2023-02-25 15:11:24,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-02-25 15:11:24,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-02-25 15:11:24,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2023-02-25 15:11:24,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2023-02-25 15:11:24,669 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-02-25 15:11:24,707 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-02-25 15:11:24,729 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-02-25 15:11:24,756 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-02-25 15:11:24,758 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-02-25 15:11:24,759 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-25 15:11:24,759 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-25 15:11:24,807 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42829
2023-02-25 15:11:24,807 INFO org.mortbay.log: jetty-6.1.26
2023-02-25 15:11:25,059 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:42829
2023-02-25 15:11:25,686 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-02-25 15:11:25,699 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-02-25 15:11:25,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ganesh
2023-02-25 15:11:25,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-02-25 15:11:25,875 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-02-25 15:11:25,982 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-02-25 15:11:26,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-02-25 15:11:26,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-02-25 15:11:26,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-02-25 15:11:26,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2023-02-25 15:11:26,396 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-02-25 15:11:26,401 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-02-25 15:11:27,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2023-02-25 15:11:27,368 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2023-02-25 15:11:27,417 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on home/ganesh/Desktop/HADOOP_F2/in_use.lock acquired by nodename 4013@ganesh-virtual-machine
2023-02-25 15:11:27,628 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-133797978-127.0.1.1-1675826040519
2023-02-25 15:11:27,629 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519
2023-02-25 15:11:27,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=648504085;bpid=BP-133797978-127.0.1.1-1675826040519;lv=-57;nsInfo=lv=-63;cid=CID-4db4ccb7-1da9-415d-86dd-c8681c9bf408;nsid=648504085;c=1675826040519;bpid=BP-133797978-127.0.1.1-1675826040519;dnuuid=4e10373a-8afa-4846-a4e7-48202a2a517c
2023-02-25 15:11:27,828 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-3162c58e-bc52-4f4c-9217-6d1817d697b3
2023-02-25 15:11:27,828 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - home/ganesh/Desktop/HADOOP_F2/current, StorageType: DISK
2023-02-25 15:11:27,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-02-25 15:11:27,907 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2023-02-25 15:11:27,907 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-133797978-127.0.1.1-1675826040519
2023-02-25 15:11:27,911 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-25 15:11:27,994 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-133797978-127.0.1.1-1675826040519 on /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 83ms
2023-02-25 15:11:27,995 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-133797978-127.0.1.1-1675826040519: 88ms
2023-02-25 15:11:28,004 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current...
2023-02-25 15:11:28,005 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/replicas doesn't exist 
2023-02-25 15:11:28,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-133797978-127.0.1.1-1675826040519 on volume /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current: 62ms
2023-02-25 15:11:28,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 73ms
2023-02-25 15:11:28,283 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(home/ganesh/Desktop/HADOOP_F2, DS-3162c58e-bc52-4f4c-9217-6d1817d697b3): no suitable block pools found to scan.  Waiting 281706487 ms.
2023-02-25 15:11:28,294 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/25/23 3:29 PM with interval of 21600000ms
2023-02-25 15:11:28,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2023-02-25 15:11:28,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-133797978-127.0.1.1-1675826040519 (Datanode Uuid 4e10373a-8afa-4846-a4e7-48202a2a517c) service to localhost/127.0.0.1:9000 successfully registered with NN
2023-02-25 15:11:28,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-02-25 15:11:28,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x26c2291b5bf1aa8f,  containing 1 storage report(s), of which we sent 1. The reports had 18 total blocks and used 1 RPC(s). This took 10 msec to generate and 164 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-25 15:11:28,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-25 15:27:34,462 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26439ms
No GCs detected
2023-02-25 15:31:10,911 ERROR org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Error compiling report
java.util.concurrent.ExecutionException: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.getDiskReport(DirectoryScanner.java:735)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.scan(DirectoryScanner.java:586)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.reconcile(DirectoryScanner.java:567)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.run(DirectoryScanner.java:512)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfo.getSuffix(DirectoryScanner.java:290)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfo.<init>(DirectoryScanner.java:306)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:899)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:872)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:872)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:820)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:782)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	... 3 more
2023-02-25 15:31:10,918 ERROR org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Exception during DirectoryScanner execution - will continue next cycle
java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.getDiskReport(DirectoryScanner.java:745)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.scan(DirectoryScanner.java:586)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.reconcile(DirectoryScanner.java:567)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.run(DirectoryScanner.java:512)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.getDiskReport(DirectoryScanner.java:735)
	... 10 more
Caused by: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfo.getSuffix(DirectoryScanner.java:290)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfo.<init>(DirectoryScanner.java:306)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:899)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:872)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:872)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:820)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:782)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	... 3 more
2023-02-25 15:39:05,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741850_1029 src: /127.0.0.1:35864 dest: /127.0.0.1:50010
2023-02-25 15:39:05,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:35864, dest: /127.0.0.1:50010, bytes: 940214, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-172272379_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741850_1029, duration: 19177994
2023-02-25 15:39:05,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741850_1029, type=LAST_IN_PIPELINE terminating
2023-02-25 15:48:15,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741851_1030 src: /127.0.0.1:40080 dest: /127.0.0.1:50010
2023-02-25 15:48:15,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:40080, dest: /127.0.0.1:50010, bytes: 425448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1011363550_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741851_1030, duration: 16585828
2023-02-25 15:48:15,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741851_1030, type=LAST_IN_PIPELINE terminating
2023-02-25 17:11:47,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x26c2291b5bf1aa90,  containing 1 storage report(s), of which we sent 1. The reports had 20 total blocks and used 1 RPC(s). This took 2 msec to generate and 17 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-25 17:11:47,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-25 19:27:41,600 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1129ms
No GCs detected
2023-02-25 21:16:27,380 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1306ms
No GCs detected
2023-02-25 21:31:51,507 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2197ms
No GCs detected
2023-02-25 21:48:39,063 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 49739ms
No GCs detected
2023-02-25 22:13:35,785 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1054ms
No GCs detected
2023-02-25 22:14:52,461 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 49618ms
No GCs detected
2023-02-26 13:32:50,511 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4124ms
No GCs detected
2023-02-26 14:21:12,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741852_1031 src: /127.0.0.1:45964 dest: /127.0.0.1:50010
2023-02-26 14:21:12,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:45964, dest: /127.0.0.1:50010, bytes: 951033, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1183127592_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741852_1031, duration: 25362133
2023-02-26 14:21:12,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741852_1031, type=LAST_IN_PIPELINE terminating
2023-02-26 14:31:58,415 ERROR org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Error compiling report
java.util.concurrent.ExecutionException: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.getDiskReport(DirectoryScanner.java:735)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.scan(DirectoryScanner.java:586)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.reconcile(DirectoryScanner.java:567)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.run(DirectoryScanner.java:512)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfo.getSuffix(DirectoryScanner.java:290)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfo.<init>(DirectoryScanner.java:306)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:899)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:872)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:872)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:820)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:782)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	... 3 more
2023-02-26 14:31:58,423 ERROR org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Exception during DirectoryScanner execution - will continue next cycle
java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.getDiskReport(DirectoryScanner.java:745)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.scan(DirectoryScanner.java:586)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.reconcile(DirectoryScanner.java:567)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.run(DirectoryScanner.java:512)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.getDiskReport(DirectoryScanner.java:735)
	... 10 more
Caused by: java.lang.RuntimeException: home/ganesh/Desktop/HADOOP_F2 is not a prefix of /home/ganesh/hadoop-2.8.1/home/ganesh/Desktop/HADOOP_F2/current/BP-133797978-127.0.1.1-1675826040519/current/finalized/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfo.getSuffix(DirectoryScanner.java:290)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfo.<init>(DirectoryScanner.java:306)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:899)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:872)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:872)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:820)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:782)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	... 3 more
2023-02-26 14:36:19,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-133797978-127.0.1.1-1675826040519:blk_1073741853_1032 src: /127.0.0.1:43812 dest: /127.0.0.1:50010
2023-02-26 14:36:19,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:43812, dest: /127.0.0.1:50010, bytes: 428493, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1321213996_1, offset: 0, srvID: 4e10373a-8afa-4846-a4e7-48202a2a517c, blockid: BP-133797978-127.0.1.1-1675826040519:blk_1073741853_1032, duration: 27112186
2023-02-26 14:36:19,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-133797978-127.0.1.1-1675826040519:blk_1073741853_1032, type=LAST_IN_PIPELINE terminating
2023-02-26 14:47:39,768 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1280ms
No GCs detected
2023-02-26 15:20:30,066 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1302ms
No GCs detected
2023-02-26 15:23:08,465 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 23030ms
No GCs detected
2023-02-26 16:21:58,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x26c2291b5bf1aa91,  containing 1 storage report(s), of which we sent 1. The reports had 22 total blocks and used 1 RPC(s). This took 2 msec to generate and 81 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-02-26 16:21:58,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-133797978-127.0.1.1-1675826040519
2023-02-26 17:21:38,344 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26865ms
No GCs detected
